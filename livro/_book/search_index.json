[
["index.html", "Como faz no R Cap√≠tulo 1 Introdu√ß√£o ", " Como faz no R Curso-R 19 de January de 2019 Cap√≠tulo 1 Introdu√ß√£o "],
["1-1-objetivos.html", "1.1 Por qu√™ ler esse livro", " 1.1 Por qu√™ ler esse livro "],
["1-2-organizacao.html", "1.2 Organiza√ß√£o", " 1.2 Organiza√ß√£o "],
["2-analises.html", "Cap√≠tulo 2 An√°lises", " Cap√≠tulo 2 An√°lises "],
["3-tutoriais.html", "Cap√≠tulo 3 Tutoriais", " Cap√≠tulo 3 Tutoriais "],
["4-modelagem.html", "Cap√≠tulo 4 Modelagem ", " Cap√≠tulo 4 Modelagem "],
["4-1-monty-hall-e-diagramas-de-influencia.html", "4.1 Monty hall e diagramas de influ√™ncia", " 4.1 Monty hall e diagramas de influ√™ncia Voc√™ est√° num jogo na TV e o apresentador pede para escolher uma entre 3 portas. Atr√°s de uma dessas portas tem uma Ferrari e nas outras duas temos cabras. Voc√™ escolhe uma porta. Depois, o apresentador retira uma porta que tem uma cabra e pergunta: voc√™ quer trocar de porta? A princ√≠pio, voc√™ pode achar que sua probabilidade de ganhar √© 1/2, j√° que uma das portas foi retirada, ent√£o n√£o importa se voc√™ troca ou n√£o. Mas a resposta √© que sim, vale √† pena trocar de porta! A probabilidade de vencer o jogo trocando a porta √© de 2/3. Figura 3.1: Brincadeira do XKCD. O problema de Monty Hall √© talvez o mais eloquente exemplo de como a probabilidade pode confundir a mente humana. Esse problema desafiou a comunidade cient√≠fica no final do s√©culo XX e chegou at√© a ser considerado um paradoxo. Recomendo ler o livro O Andar do B√™bado, de Leonard Mlodinow, que conta essa e muitas outras hist√≥rias interessantes sobre a probabilidade. Existem v√°rias formas de explicar por qu√™ trocar a porta √© a melhor estrat√©gia. A que eu mais gosto √© a do pr√≥prio Andar do B√™bado, que mostra que, quando voc√™ escolhe a primeira porta, voc√™ est√° apostando se acertou ou n√£o a Ferrari. Se voc√™ apostar que acertou a Ferrari, n√£o deve trocar a porta e, se voc√™ apostar que errou a Ferrari, deve trocar. A aposta de errar a Ferrari de primeira tem probabilidade 2/3, logo, vale √† pena trocar. Nesse post, mostramos uma solu√ß√£o alternativa, simples e elegante para o problema usando diagramas de influ√™ncia e o pacote bnlearn. 4.1.1 Redes bayesianas As redes Bayesianas s√£o o resultado da combina√ß√£o de conceitos probabil√≠sticos e conceitos da teoria dos grafos. Segundo Pearl, tal uni√£o tem como consequ√™ncias tr√™s benef√≠cios: i) prover formas convenientes para expressar suposi√ß√µes do modelo; ii) facilitar a representa√ß√£o de fun√ß√µes de probabilidade conjuntas; e iii) facilitar o c√°lculo eficiente de infer√™ncias a partir de observa√ß√µes. Da teoria de probabilidades precisamos apenas de alguns resultados b√°sicos sobre probabilidade condicional. Primeiramente, pela defini√ß√£o de probabilidade condicional, sabemos que \\[ p(x_1, x_2) = p(x_1)p(x_2|x_1). \\] Aplicando essa regra iterativamente para \\(n\\) vari√°veis, temos \\[ p(x_1, \\dots, x_p) = \\prod_j p(x_j|x_1,\\dots, x_{j-1}). \\] Agora, imagine que, no seu problema, a vari√°vel aleat√≥ria \\(X_j\\) n√£o dependa probabilisticamente de todas as vari√°veis \\(X_1,\\dots, X_{j-1}\\), e sim apenas de um subconjunto \\(\\Pi_j\\) dessas vari√°veis. Fazendo isso, a equa√ß√£o pode ser escrita como \\[ p(x_1, \\dots, x_p) = \\prod_j p(x_j|\\pi_j). \\] Chamamos \\(\\Pi_j\\) de pais de \\(X_j\\). Esse conjunto pode ser pensado como as vari√°veis que s√£o suficientes para determinar as probabilidades de \\(X_j\\). A parte mais legal das redes Bayesianas √© que elas podem ser representadas a partir de DAGs (grafos direcionados ac√≠clicos). No grafo, se \\(X_1\\) aponta para \\(X_2\\), ent√£o \\(X_1\\) √© pai de \\(X_2\\). Por exemplo, esse grafo aqui representa a distribui√ß√£o de probabilidades \\(p(x_1, \\dots, x_5)\\) com \\[ p(x_1, \\dots, x_5) = p(x_1)p(x_2|x_1)p(x_3|x_1)p(x_4|x_3,x_2)p(x_5|x_4). \\] 4.1.2 Diagrama de influ√™ncias Um diagrama e influ√™ncias √© uma rede Bayesiana com n√≥s de decis√£o e utilidade (ganhos). Ou seja, √© uma jun√ß√£o de tr√™s conceitos: \\[ \\underbrace{\\text{prob. condicional} + \\text{grafos}}_{\\text{rede Bayesiana}} + \\text{teoria da decis√£o} = \\text{diagrama de influ√™ncias} \\] Na teoria da decis√£o, usualmente estamos interessados em maximizar a utilidade esperada. No diagrama, considerando a estrutura de probabilidades dada pela rede Bayesiana e as informa√ß√µes dispon√≠veis, queremos escolher a decis√£o que faz com que, em m√©dia, nosso retorno seja mais alto. Com diagramas de influ√™ncias, √© poss√≠vel organizar sistemas complexos com m√∫ltiplas decis√µes, considerando diferentes conjuntos de informa√ß√µes dispon√≠veis. √â uma ferramenta realmente muito poderosa. 4.1.3 Voltando ao Monty Hall Agora que sabemos um pouquinho de diagramas de influ√™ncia, podemos desenhar o do Monty Hall: O jogador tem duas decis√µes a tomar: \\(D_1\\) (escolha_inicial): A escolha da porta inicial (1, 2, 3). \\(D_2\\) (trocar): Trocar a porta ou n√£o (s, n). Tamb√©m temos duas fontes de incerteza: \\(X_1\\) (ferrari): Em qual porta est√° a Ferrari (1, 2, 3). \\(X_2\\) (porta_retirada): Qual porta foi retirada (1, 2, 3). Essa vari√°vel n√£o √© sempre aleat√≥ria: se eu escolho a porta 1 e a Ferrari est√° em 2, o apresentador √© obrigado a retirar a porta 3. Se o apresentador tiver a op√ß√£o de escolher (que acontece no caso da escolha inicial ser a Ferrari), o apresentador escolhe uma porta para retirar aleatoriamente. Finalmente, temos um n√≥ de utilidade: \\(U_1\\) (result): Ganhei a Ferrari (ganhei, perdi). Em R, podemos construir a rede Bayesiana do problema utilizando o pacote bnlearn: FALSE [,1] [,2] FALSE [1,] &quot;escolha_inicial&quot; &quot;porta_retirada&quot; FALSE [2,] &quot;ferrari&quot; &quot;porta_retirada&quot; FALSE [3,] &quot;porta_retirada&quot; &quot;trocar&quot; FALSE [4,] &quot;trocar&quot; &quot;result&quot; FALSE [5,] &quot;ferrari&quot; &quot;result&quot; FALSE [6,] &quot;escolha_inicial&quot; &quot;result&quot; O output desse conjunto de opera√ß√µes √© um objeto do tipo bn com v√°rias propriedades pr√© calculadas pelo pacote bnlearn: Random/Generated Bayesian network model: [escolha_inicial][ferrari][porta_retirada|escolha_inicial:ferrari][trocar|porta_retirada] [result|escolha_inicial:ferrari:trocar] nodes: 5 arcs: 6 undirected arcs: 0 directed arcs: 6 average markov blanket size: 3.60 average neighbourhood size: 2.40 average branching factor: 1.20 generation algorithm: Empty Com as especifica√ß√£o do problema dada, se gerarmos aleatoriamente todos os cen√°rios, chegamos √† essa combina√ß√£o de casos equiprov√°veis (ver Extra 2) Agora, vamos escrever todas as combina√ß√µes poss√≠veis de cen√°rios e guardar num data.frame chamado dados: escolha_inicial ferrari porta_retirada trocar result 1 1 2 n ganhei 1 1 2 s perdi 1 1 3 n ganhei 1 1 3 s perdi 1 2 3 n perdi 1 2 3 s ganhei 1 3 2 n perdi 1 3 2 s ganhei 2 1 3 n perdi 2 1 3 s ganhei 2 2 1 n ganhei 2 2 1 s perdi 2 2 3 n ganhei 2 2 3 s perdi 2 3 1 n perdi 2 3 1 s ganhei 3 1 2 n perdi 3 1 2 s ganhei 3 2 1 n perdi 3 2 1 s ganhei 3 3 2 n ganhei 3 3 2 s perdi 3 3 1 n ganhei 3 3 1 s perdi Finalmente, ajustamos nossa rede Bayesiana, usando a fun√ß√£o bnlearn::bn.fit(). A fun√ß√£o bnlearn::cpquery() (conditional probability query) serve para realizar uma consulta de probabilidades dada a rede ajustada. No nosso caso, a partir de uma escolha inicial qualquer \\(d_1\\), queremos saber o ganho ao trocar √© maior que o ganho ao n√£o trocar. \\[ \\mathbb E(U_1\\; |\\; D_2 = \\text{s}, D_1 = d_1) &gt; \\mathbb E(U_1\\; |\\; D_2 = \\text{n}, D_1 = d_1). \\] Fazendo contas, isso equivale matematicamente a consultar se \\[ \\mathbb P(U_1=\\text{ganhei}\\; |\\; D_2 = \\text{s}) &gt; \\mathbb P(U_1=\\text{ganhei}\\; |\\; D_2 = \\text{n}) \\] Agora, podemos consultar \\(\\mathbb P(U_1=\\text{ganhei}\\; |\\; D_2 = \\text{s})\\) com nosso modelo! [1] 0.6666704 E n√£o √© que d√° 2/3 mesmo? Da mesma forma, temos [1] 0.3333187 Resolvido! 4.1.4 Wrap-up Vale √† pena trocar a porta! Redes Bayesianas juntam grafos e probabilidades condicionais Diagramas de influ√™ncia juntam redes Bayesianas e teoria da decis√£o Essas ferramentas podem ser utilizadas tanto para resolver Monty Hall quanto para ajudar em sistemas complexos. √â isso pessoal. Happy coding ;) 4.1.5 Extra Se voc√™ ficou interessada em como eu fiz o diagrama, utilizei o pacote DiagrammeR. O c√≥digo est√° aqui: 4.1.6 Extra 2 √â poss√≠vel simular os dados que coloquei no post com uma fun√ß√£o simples, que adicionei abaixo. Na verdade, o fato de eu ter considerado somente as combina√ß√µes √∫nicas de cen√°rios e n√£o os dados simulados abaixo √© um pouco roubado, e s√≥ funciona porque os cen√°rios calham de ser, de fato, equiprov√°veis. Observations: 10,000 Variables: 5 $ escolha_inicial &lt;fct&gt; 3, 1, 2, 1, 1, 1, 3, 1, 2, 3, 3, 1, 3, 1, 2, 2, 2,... $ ferrari &lt;fct&gt; 1, 1, 2, 1, 1, 2, 3, 3, 1, 2, 3, 3, 2, 1, 1, 3, 1,... $ porta_retirada &lt;fct&gt; 2, 3, 1, 3, 2, 3, 2, 2, 3, 1, 1, 2, 1, 2, 3, 1, 3,... $ trocar &lt;fct&gt; n, s, s, n, s, n, n, n, n, s, s, s, s, n, n, s, n,... $ result &lt;fct&gt; perdi, perdi, perdi, ganhei, perdi, perdi, ganhei,... Os dados do post podem ser obtidos fazendo isso aqui: Agradecimentos: Rafael Stern, que me convenceu de que vale √† pena mostrar os dados simulados üòâ "],
["4-2-construindo-autoencoders.html", "4.2 Construindo Autoencoders", " 4.2 Construindo Autoencoders Autoencoders s√£o redes neurais treinadas com o objetivo de copiar o seu input para o seu output. Esse interesse pode parecer meio estranho, mas na pr√°tica o objetivo √© aprender representa√ß√µes (encodings) dos dados, que podem ser usadas para redu√ß√£o de dimensionalidade ou at√© mesmo compress√£o de arquivos. Basicamente, um autoencoder √© dividido em duas partes: um encoder que √© uma fun√ß√£o \\(f(x)\\) que transforma o input para uma representa√ß√£o \\(h\\) um decoder que √© uma fun√ß√£o \\(g(x)\\) que transforma a representa√ß√£o \\(h\\) em sua reconstru√ß√£o \\(r\\) Imagem do blog do Keras 4.2.1 Construindo o seu primeiro autoencoder Nesse pequeno tutorial, vou usar o keras para definir e treinar os nossos autoencoders. Como base de dados vou usar algumas simula√ß√µes e o banco de dados mnist (famoso para todos que j√° mexeram um pouco com deep learning). O mnist √© um banco de dados de imagens de tamanho 28x28 de d√≠gitos escritos √† m√£o. Esse dataset promoveu grandes avan√ßos na √°rea de reconhecimento de imagens. Com esse c√≥digo definimos um modelo da seguinte forma: \\[ X = (X*W_1 + b_1)*W_2 + b_2 \\] Em que: \\(X\\) √© o nosso input com dimens√£o (?, 784) \\(W_1\\) √© uma matriz de pesos com dimens√µes (784, 32) \\(b_1\\) √© uma matriz de forma (?, 32) \\(W_2\\) √© uma matriz de pesos com dimens√µes (32, 784) \\(b_2\\) √© uma matriz de forma (?, 784) Note que ? aqui √© o n√∫mero de observa√ß√£oes da base de dados. Agora vamos estimar \\(W_1\\), \\(W_2\\), \\(b_1\\) e \\(b_2\\) de modo a minimizar alguma fun√ß√£o de perda. Inicialmente vamos usar a binary crossentropy por pixel que √© definida por: \\[-\\sum_{i=1}y_i*log(\\hat{y}_i)\\] Isso √© definido no keras usando: N√£o vou entrar em detalhes do que √© o adadelta, mas √© uma varia√ß√£o do m√©todo de otimiza√ß√£o conhecido como gradient descent. Agora vamos carregar a base de dados e em seguida treinar o nosso autoencoder`. Estimamos os par√¢metros desse modelo no keras fazendo: Depois de rodar todas as itera√ß√µes, voc√™ poder√° usar o seu encoder e o seu decoder para entender o que eles fazem com as imagens. Veja o exemplo a seguir em que vamos obter os encodings para as 10 primeiras imagens da base de teste e depois reconstruir a imagem usando o decoder. FALSE [1] 10 32 FALSE [1] 0.0000000 10.1513205 3.5742311 2.6635208 6.3097358 3.4840517 FALSE [7] 9.1041250 6.6329145 1.6385922 9.8017225 9.5529270 1.6670935 FALSE [13] 5.7208562 4.8035479 3.9149191 0.6408147 1.2716029 3.1215091 FALSE [19] 13.7575903 0.0000000 1.8692881 3.2142215 0.7444992 5.0728440 FALSE [25] 8.2932110 9.9866810 2.7651572 11.1291723 5.2460670 5.6875997 FALSE [31] 10.6097431 3.6338394 O encoder transforma a matriz de (10, 784) para uma matriz com dimensao (10, 2). Podemos reconstruir a imagem, a pardir da imagem que foi comprimida usando o nosso decoder. Compare as reconstru√ß√µes com as imagens originais abaixo: Um ponto interessante √© que esse modelo faz uma aproxima√ß√£o da solu√ß√£o por componentes principais! Na verdade, a defini√ß√£o do quanto s√£o parecidos √© quase-equivalente. Isso quer dizer que os pesos \\(W\\) encontrados pelo PCA e pelo autoencoder ser√£o diferentes, mas o sub-espa√ßo criado pelos mesmos ser√° equivalente. Se s√£o equivalentes, qual a vantagem de usar autoencoders ao inv√©s de PCA? O PCA para por aqui, voc√™ define que ser√£o apenas rela√ß√µes lineares, e voc√™ reduz dimens√£o apenas reduzindo o tamanho da matriz. Em autoencoders voc√™ tem diversas outras sa√≠das para aprimorar o m√©todo. A primeira delas √© simplesmente adicionar uma condi√ß√£o de esparsidade nos pesos. Isso vai reduzir o tamanho do vetor latente (como √© chamada a camada do meio do autoencoder) tamb√©m, pois ele ter√° mais zeros. Isso pode ser feito rapidamente com o keras. Basta adicionar um activity_regularizer em nossa camada de encoding. Isso vai adicionar na fun√ß√£o de perda um termo que toma conta do valor dos outputs da camada intermedi√°ria. Outra forma de melhorar o seu autoencoder √© permitir que o encoder e o decoder sejam redes neurais profundas. Com isso, ao inv√©s de tentar encontrar transforma√ß√µes lineares, voc√™ permitir√° que o autoencoder encontre transforma√ß√µes n√£o lineares. Mais uma vez fazemos isso com o keras: Existem formas ainda mais inteligentes de construir esses autoencoders, mas o post iria ficar muito longo e n√£o ia sobrar asssunto para o pr√≥ximo. Se voc√™ quiser saber mais, recomendo fortemente a leitura deste artigo do blog do Keras e desse cap√≠tulo. Uma fam√≠lia bem moderna de autoencoders s√£o os VAE (Variational Autoencoders). Esses autoencoders aprendem modelos de vari√°veis latentes. Isso √© interessante porque permite que voc√™ gere novos dados, parecidos com os que voc√™ usou para treinar o seu autoencoder. Voc√™ pode encontrar uma implementa√ß√£o desse modelo aqui. "],
["4-3-modelos-beseados-em-arvores-e-a-multicolinearidade.html", "4.3 Modelos beseados em √°rvores e a multicolinearidade", " 4.3 Modelos beseados em √°rvores e a multicolinearidade Modelos baseados em √°rvores como √°rvores de decis√£o, random forest, ligthGBM e xgboost s√£o conhecidos, dentre outras qualidades, pela sua robust√™s diante do problema de multicolinearidade. √â sabido que seu poder preditivo n√£o se abala na presen√ßa de vari√°veis extremamente correlacionadas. Por√©m, quem nunca usou um Random Forest pra fazer sele√ß√£o de vari√°veis? Pegar, por exemplo, as top 10 mais importantes e descartar o resto? Ou at√© mesmo arriscou uma interpreta√ß√£o e concluiu sobre a ordem das vari√°veis mais importantes? Abaixo mostraremos o porqu√™ n√£o devemos ignorar a quest√£o da multicolinearidade completamente! 4.3.1 Um modelo bonitinho Primeiro vamos ajustar um modelo bonitinho, livre de multicolinearidade. Suponha que queiramos prever Petal.Length utilizando as medidas das s√©palas (Sepal.Width e Sepal.Length) da nossa boa e velha base iris. O gr√°fico acima mostra que as vari√°veis explicativas n√£o s√£o fortemente correlacionadas. Ajustando uma random fores, temos a seguinte ordem de import√¢ncia das vari√°veis: Sem surpresas. Agora vamos para o problema! 4.3.2 Um modelo com feinho Vamos forjar uma situa√ß√£o extrema em que muitas vari√°veis sejam multicolineares. Vou fazer isso repetindo a coluna Sepal.Length v√°rias vezes. Agora a coisa t√° feia! Temos 20 vari√°veis perfeitamente colineares. Mesmo assim um random forest nessa nova base n√£o perderia poder preditivo. Mas como ficou a import√¢ncia das vari√°veis? Aqui o jogo j√° se inverteu: concluir√≠amos que Sepal.Width √© mais importante de todas as vari√°veis! 4.3.3 Sele√ß√£o de vari√°veis furado O gr√°fico abaixo mostra que quanto mais vari√°veis correlacionadas tivermos, menor a import√¢ncia de TODAS ELAS SIMULTANEAMENTE! √â como se as vari√°veis colineares repartissem a import√¢ncia entre elas. Na pr√°tica, se estabelecessemos um corte no valor de import√¢ncia pra descartar vari√°veis (como ilustrado pela linha vermelha), ter√≠amos um problema em potencial: poder√≠amos estar jogando fora informa√ß√£o muito importante. 4.3.4 Como tratar multicolinearidade, ent√£o? Algumas maneiras de lidar com multicolinearidade s√£o: Observar a matriz de correla√ß√£o VIF Recursive feature elimination 4.3.5 Conclus√£o Cuidado ao jogar tudo no caldeir√£o! Devemos sempre nos preocupar com multicolinearidade, mesmo ajustando modelos baseados em √°rvores. "],
["4-4-woe-em-r-com-tidywoe.html", "4.4 WoE em R com tidywoe", " 4.4 WoE em R com tidywoe WoE (weight of evidence) √© uma ferramenta bastante usada em aplica√ß√µes de regress√£o log√≠stica, principalmente na √°rea de score de cr√©dito. Simploriamente falando, ele transforma categorias em n√∫meros que refletem a diferen√ßa entre elas pelo crit√©rio de separa√ß√£o do Y = 1 e Y = 0. Se voc√™ ainda n√£o sabe o que √© ou quer ler mais sobre o assunto, um texto que eu gostei de ler: Data Exploration with Weight of Evidence and Information Value in R O autor desse texto √© o Kim Larsen, criador do pacote Information que √© completo e cheio de ferramentas sofisticadas em torno do WoE. Por√©m, no dia a dia do meu trabalho volta e meia eu tinha que construir rotinas pr√≥prias para fazer as vers√µes em WoE das minhas vari√°veis, mesmo com v√°rios pacotes completos dispon√≠veis. A principal motiva√ß√£o era que eles n√£o eram muito pr√°ticos e n√£o se encaixavam na filosofia do tidyverse. Da√≠ acabei juntando essas rotinas num pacote chamado tidywoe e deixando no ar. A ideia √© que ela fa√ßa o analista ganhar em tempo, legibilidade e reprodutibilidade. Abaixo segue como usar. 4.4.1 Instala√ß√£o e dados Para instalar, basta rodar abaixo. # install.packages(&quot;devtools&quot;) devtools::install_github(&quot;athospd/tidywoe&quot;) library(tidyverse) library(tidywoe) # install.packages(&quot;FactoMineR&quot;) data(tea, package = &quot;FactoMineR&quot;) tea_mini &lt;- tea %&gt;% select(breakfast, how, where, price) 4.4.2 Como usar Tem duas fun√ß√µes que importam: - add_woe() - adiciona os woe‚Äôs num data frame. - woe_dictionary() - cria dicion√°rio que mapeia as categorias com os woe‚Äôs. 4.4.3 add_woe() A fun√ß√£o add_woe() serve para adicionar as vers√µes WoE‚Äôs das vari√°veis em sua amostra de dados. tea_mini %&gt;% add_woe(breakfast) breakfast how where price how_woe where_woe price_woe breakfast tea bag chain store p_unknown -0.0377403 -0.0451204 -0.2564295 breakfast tea bag chain store p_variable -0.0377403 -0.0451204 0.1872882 Not.breakfast tea bag chain store p_variable -0.0377403 -0.0451204 0.1872882 Not.breakfast tea bag chain store p_variable -0.0377403 -0.0451204 0.1872882 Voc√™ pode selecionar as vari√°veis que vc quiser selecionando-as como se fosse no dplyr::select(). tea_mini %&gt;% add_woe(breakfast, where:price) 4.4.4 woe_dictionary() A fun√ß√£o woe_dictionary() √© uma das duas partes necess√°rias para fazer o add_woe() funcionar (a outra parte s√£o os dados). Ele constr√≥i o dicion√°rio de categorias e seus respectivos woe‚Äôs. tea_mini %&gt;% woe_dictionary(breakfast) variable explanatory n_tot n_breakfast n_Not.breakfast p_breakfast p_Not.breakfast woe how tea bag 170 80 90 0.5555556 0.5769231 -0.0377403 how tea bag+unpackaged 94 50 44 0.3472222 0.2820513 0.2078761 how unpackaged 36 14 22 0.0972222 0.1410256 -0.3719424 where chain store 192 90 102 0.6250000 0.6538462 -0.0451204 4.4.5 Usando um dicion√°rio customizado Muitas vezes h√° o interesse em ajustar na m√£o alguns valores de woe para consertar a ordem dos efeitos de uma dada vari√°vel ordinal. Esse √© o motivo de o add_woe() poder receber um dicion√°rio passado pelo usu√°rio. Isso se faz por meio do argumento .woe_dictionary. A maneira mais f√°cil de se fazer isso √© montar um dicion√°rio inicial com o woe_dictionary() e depois alterar os valores nele para alcan√ßar os ajustes desejados. Exemplo: # Construa um dicion√°rio inicial tea_mini_woe_dic &lt;- tea_mini %&gt;% woe_dictionary(breakfast) # Mexa um pouquinho nos woes tea_mini_woe_dic_arrumado &lt;- tea_mini_woe_dic %&gt;% mutate(woe = if_else(explanatory == &quot;p_unknown&quot;, 0, woe)) # Passe esse dicion√°rio para o add_woe() tea_mini %&gt;% add_woe(breakfast, .woe_dictionary = tea_mini_woe_dic_arrumado) breakfast how where price how_woe where_woe price_woe breakfast tea bag chain store p_unknown -0.0377403 -0.0451204 0.0000000 breakfast tea bag chain store p_variable -0.0377403 -0.0451204 0.1872882 Not.breakfast tea bag chain store p_variable -0.0377403 -0.0451204 0.1872882 Not.breakfast tea bag chain store p_variable -0.0377403 -0.0451204 0.1872882 4.4.6 Exemplo de explora√ß√£o O woe_dictionary() devolve uma tabela arrumada, bem conveniente para explorar mais. Por exemplo, a tabela est√° pronta para o ggplot. Aqui est√° o github do pacote para contribui√ß√µes. Pretendo colocar bastante coisa nova no pacote ainda. "],
["4-5-regressao-logistica-em-a-menor-deep-learning-do-mundo.html", "4.5 Regress√£o Log√≠stica em: a menor deep learning do mundo", " 4.5 Regress√£o Log√≠stica em: a menor deep learning do mundo 4.5.1 Objetivos A finalidade do post √©: aprender a fazer uma regress√£o log√≠stica com o keras aprender a fazer um PCA com o keras aproximar o Deep Learning do que j√° havia de conhecido pela maioria dos analistas de dados. instigar a todos que vieram antes do deep learning a estudar e a ficar √† vontade com as novidades em torno dela. mostrar que muitos profissionais inseridos na √°rea de machine learning j√° conheciam grande parte do que o deep learning usa. levantar discuss√£o sobre alguns mitos que n√£o s√£o construtivos para a comunidade dos analistas de dados. 4.5.2 Motiva√ß√£o Li estat√≠sticos, cientistas da computa√ß√£o, engenheiros de dados a afins questionando o futuro do Machine Learning e se tudo que conhec√≠amos antes sobre modelagem estat√≠stica havia ficado obsoleto (como essa pergunta no Quora: Should I Quit Machine Learning?). E em conversas com pessoas pr√≥ximas percebia certa ufania pela novidade e frustra√ß√£o pela ‚Äúobsol√™ncia‚Äù do que se havia investido tempo estudando antes. Para piorar, aproveitadores pegaram jacar√© nessa onda para fazer marketing malicioso com o intuito de desvalorizar e dividir a comunidade dos analistas de dados. Algo bem similar com o que aconteceu com outras palavras da moda como data science, big data, Python versus R e a pr√≥pria machine learning. Antes havia a cl√°ssica propaganda de que a empresa X utilizava MACHINE LEARNING em vez de modelos preditivos. Agora a coisa evoluiu e apelam para o uso da palavra Deep Learning. O que realmente importa: Deep Learning √© uma grande novidade e colocou a Intelig√™ncia Artificial em evid√™ncia. Quem manjava Machine Learning antes vai conseguir aplicar 95% do seu conhecimento nas aplica√ß√µes de Deep Learning (incluindo bayesianismo, bootstrap, infer√™ncia, probabilidade e a boiada toda). Deep Learning tem que ser visto como uma ferramenta a mais na caixa do analista de dados e n√£o um substituto. E para abordar essa quest√£o resolvi ajustar uma regress√£o log√≠stica usando deep learning para que todos que j√° fizeram uma regress√£o log√≠stica antes possam dizer que j√° fizeram uma rede neural tamb√©m! Confesso ter uma leve motiva√ß√£o provocativa, mas qual gra√ßa teria se assim n√£o fosse? =P 4.5.3 O que faremos Regress√£o log√≠stica para \\(Y_1\\) (com glm) Deep Learning para \\(Y_1\\) (com keras) Mostrar que regress√£o log√≠stica n√£o √© o melhor para \\(Y_2\\) e que Deep Learning vai al√©m da limita√ß√£o dos modelos lineares (com glm) Deep Learning para \\(Y_2\\) (com keras) M√£os √† obra. 4.5.4 Pacotes 4.5.5 Regress√£o log√≠stica versus Deep Learning Hora de ajustar modelos para os mesmos dados de duas maneiras diferentes: regress√£o log√≠stica com glm e deep learning com o keras. 4.5.6 Dados simulados O c√≥digo acima criou duas vari√°veis respostas (targets). Em representa√ß√£o matem√°tica, elas possuem as seguintes defini√ß√µes: Resposta y_1 \\[E[Y_1|x] = \\text{logistic}{(-1 + 2x)} = \\frac{1}{1 + e^{{-(-1 + 2x)}}}\\] Resposta y_2 \\[E[Y_2|x] = \\text{logistic}{(-1 + 2\\tanh(-1 + 2x))} = \\frac{1}{1 + e^{{-(-1 + 2\\tanh(-1 + 2x))}}}\\] \\(x\\) √© linear no logito de y_1, ent√£o a regress√£o log√≠stica vai cair bem para descobrir os par√¢metros \\(-1\\) e \\(2\\). Por√©m, \\(x\\) n√£o √© linhar no logito de y_2 e por isso a regress√£o log√≠stica n√£o conseguir√° representar fielmente o gerador de y_2. OBS 1: A forma \\(\\text{logistic}{(\\beta_0 + \\beta_1\\tanh(\\beta_2 + \\beta_3X))}\\) tem par√¢metros dentro do fun√ß√£o tanh, o que significa que a nossa hip√≥tese para \\(E[Y_2|x]\\) n√£o √© mais linear nos par√¢metros. Por isso que modelos lineares (como o nome sugere) n√£o s√£o mais indicados. E a n√£o linearidade √© uma das generaliza√ß√µes que as redes neurais nos fornece! (sim, isso √© muito relevante) OBS 2: √© claro que nesse caso bem simples de uma vari√°vel conseguir√≠amos inspecionar os dados para chegar em boas transforma√ß√µes de \\(x\\) de tal forma que o ajuste da log√≠stica ficasse t√£o bom quanto o de uma rede neural, mas se acrescent√°ssemos muitas outras vari√°veis a√≠ a coisa complicaria! Em representa√ß√£o de redes neurais, as f√≥rmulas acima ficam assim: Resposta y_1 Resposta y_2 O que era fun√ß√£o de liga√ß√£o no GLM, em redes neurais virou fun√ß√£o de ativa√ß√£o (no final eu falo mais sobre vocabul√°rios que mudaram). 4.5.7 Olhada nos dados O gr√°fico da direita mostra que x √© proporcional ao logito das probabilidades de y_1 (em vermelho) como era pra ser por termos constru√≠do assim. J√° com o y_2 (em azul) ainda ficou parecendo uma sigmoide mesmo depois da transforma√ß√£o. 4.5.8 Ajuste de modelos 4.5.8.1 Regress√£o log√≠stica para \\(Y_1\\) (com glm) As estimativas ficaram bem pr√≥ximas dos verdadeiros valores \\(\\beta_0 = -1\\) e \\(\\beta_1 = 2\\). A acur√°cia foi de 85%. 4.5.8.2 Deep Learning para \\(Y_1\\) (com keras) Vamos montar nossa hip√≥tese para \\(E[Y_1|x]\\). Model _____________________________________________________________ Layer (type) Output Shape Param # ============================================================= modelo_keras_1 (InputLayer) (None, 1) 0 _____________________________________________________________ camada_unica (Dense) (None, 1) 2 _____________________________________________________________ link_logistic (Activation) (None, 1) 0 ============================================================= Total params: 2 Trainable params: 2 Non-trainable params: 0 _____________________________________________________________ A hip√≥tese constru√≠da tem 2 par√¢metros. Parece que est√° certo! \\(\\beta_0\\) e \\(\\beta_1\\). Agora √© a vez da fun√ß√£o de perda. Como nosso objetivo √© construir uma regress√£o log√≠stica, n√≥s vamos escolher a fun√ß√£o de perda binary_crossentropy que √© sin√¥nimo de deviance da log√≠stica, termo mais comum no mundo da estat√≠stica. A m√©trica 'accuracy' n√£o entra no otimizador da fun√ß√£o de perda, a gente usa ela para comparar os modelos que criamos. No caso vamos comparar com o modelo glm ajustado acima (mas, por exemplo, em caso de eventos raros a 'accuracy' n√£o vai ser muito informativa, da√≠ poder√≠amos usar 'auc', 'gini', etc.). modelo_keras_1 %&gt;% compile( loss = &#39;binary_crossentropy&#39;, optimizer = optimizer_sgd(lr = 0.4), metrics = c(&#39;accuracy&#39;) ) modelo_keras_1_fit &lt;- modelo_keras_1 %&gt;% fit( x = df$x, y = df$y_1, epochs = 20, batch_size = 1000, verbose = 0 ) Resultados id√™nticos! Era para assim ser porque constru√≠mos a mesma hip√≥tese e a memsa fun√ß√£o de perda do glm. 4.5.8.3 Regress√£o log√≠stica para \\(Y_2\\) (com glm) Para modelar \\(Y_2\\) vamos pisar em terrenos que os modelos lineares n√£o pisam. Primeiro tento ajustar uma curva uasndo x e a transforma√ß√£o tanh(x). Esse preditor eu suponho que escolhi depois de uma minuciosa e demorada inspe√ß√£o dos dados (tentei simular mais ou menos o que eu faria numa modelagem onde eu que teria que construir as features na m√£o). Acur√°cia de 82%, nada mal. Mas a hip√≥tese e par√¢metros foram distintos do verdadeiro gerador dos dados. Vamos usar redes neurais para resolver o problema de n√£o linearidade. 4.5.8.4 Deep Learning para \\(Y_2\\) (com keras) Hip√≥tese para \\(E[Y_2|x]\\). Model _____________________________________________________________ Layer (type) Output Shape Param # ============================================================= modelo_keras_2 (InputLayer) (None, 1) 0 _____________________________________________________________ camada_um (Dense) (None, 1) 2 _____________________________________________________________ tanh_de_dentro (Activation) (None, 1) 0 _____________________________________________________________ camada_dois (Dense) (None, 1) 2 _____________________________________________________________ link_logistic (Activation) (None, 1) 0 ============================================================= Total params: 4.0 Trainable params: 4.0 Non-trainable params: 0.0 _____________________________________________________________ Quatro par√¢metros ‚Äòtrein√°veis‚Äô, √© isso a√≠! Dois par√¢metros de dentro do tanh e os dois par√¢metros de fora. Precisamos que o keras nos devolva -1, 2, -1 e 2 do jeito que geramos os dados. Fun√ß√£o de custo Precis√£o de 82% tamb√©m, mas agora os par√¢metros est√£o bem pr√≥ximos daqueles que geraram os dados! Acabamos de ver um conjunto de par√¢metros sendo encontrados mesmo com rela√ß√£o n√£o linear entre eles e a m√©dia. A precis√£o entre os dois modelos at√© que se equiparou, mas o gr√°fico das hip√≥teses encontradas (abaixo) mostra que a curva do glm est√° pior do que a curva do keras. 4.5.8.5 (B√¥nus) PCA com autoencoer PCA e autoencodes servem na pr√°tica para reduzir a dimensionalidade dos dados. PCA √© um caso particular de autoencoder com apenas uma camada e fun√ß√µes de ativa√ß√£o lineares. O post Construindo Autoencoders ensina a fazer e recomendo a leitura. Resumo: autoencoder √© uma t√©cnica incr√≠vel que generaliza o PCA. 4.5.9 Discuss√£o Na minha opini√£o aconteceu de que muita coisa antiga e consagrada teve seu nome mudado e apresentado como novo e isso acabou ofuscando as grandes contribui√ß√µes realmente relevantes das pesquisas em torno das redes neurais e do deep learning. Percebe-se que o Deep Learning generalizou bastante coisa e por isso eu declaro o post bem sucedido se o escrito acima despertou curiosidade em aprender mais sobre deep learning para agregar ao trabalho que j√° havia sendo feito. Vale mais a pena trazer todos os praticantes de estat√≠stica e machine learning juntos nessa novidade do que nos dividirmos. Acredito que mais do que nunca a fundamenta√ß√£o te√≥rica e interpreta√ß√µes ter√£o seu valor potencializado com a dissemina√ß√£o do deep learning. Com o mito de que deep learning seja uma panaceia e com a facilidade que ela nos trouxe para fazer um modelo preditivo, h√° o risco de sermos soterrados por caixas pretas feitas por pessoas negligentes com aspectos importantes como interpretabilidade, causalidade e generaliza√ß√£o. Talvez o bayesianismo se desponte (mais uma vez) como a solu√ß√£o para problemas qualitativos num mundo cada vez mais obscuro trazendo √† luz os excessos dos modelos complexos e os benef√≠cios dos modelos simples. Puxando o gancho do bayesianismo (e infer√™ncias em geral), os resultados j√° obtidos em cima de modelos lineares ainda se aplicam em deep learning. E tamb√©m temos a vantagem de que todas as demais ferramentas que se usam em deep learning e que n√£o afetam a linearidade dos par√¢metros podem ser utilizadas, como convolucional, recorrente, max pooling, drop out, autoencoder e tantas outras. Para finalizar, na pr√°tica sugiro aplicar deep learning com o Keras, um pacote incr√≠vel que usa o tensorflow ou o theano por tr√°s. Acredito que voc√™s ver√£o muitos posts sobre o assunto por aqui! (podem encher o saco do Dan Falbel, um dos s√≥cios da curso-r.com, que est√° envolvido no desenvolvimento desse pacote em R =]). 4.5.10 Curiosidades 4.5.11 N-√©simo menor deep learning Vimos acima o menor e o segundo menor Deep Learnings (que de profundo n√£o t√™m nada =P). Mas podemos ir o t√£o profundo quanto quisermos! A representa√ß√£o de redes neurais sai f√°cil: J√° a representa√ß√£o matem√°tica fica esquisita: \\[E[Y|x] = \\frac{1}{1 + \\exp{\\left(\\beta_{p-1} + \\beta_p\\frac{1}{\\frac{\\vdots}{1 + \\exp{\\left(\\beta_{6} + \\beta_{7}\\frac{1}{1 + \\exp{\\left(\\beta_4 + \\beta_5\\frac{1}{1 + \\exp{\\left(\\beta_2 + \\beta_3\\frac{1}{1 + \\exp{\\left(\\beta_0 + \\beta_1x\\right)}}\\right)}}\\right)}}\\right)}}}\\right)}}\\] 4.5.12 Vocabul√°rio Os jarg√µes e termos do deep learning foram herdados de um outro contexto diferente do da modelagem preditiva estudada na estat√≠stica e por isso acabaram surgindo in√∫meros sin√¥nimos. Alguns deles s√£o: fun√ß√£o de ativa√ß√£o = fun√ß√£o de liga√ß√£o Softmax = verossimilhan√ßa da multinomial sigmoide = fun√ß√£o com formato de S (no tensorflow o padr√£o √© a logistic) pesos = par√¢metros/betas/coeficientes binary crossentropy = deviance da distribui√ß√£o binomial (regress√£o log√≠stica) √â isso a√≠, temos que nos manter curiosos, questionar e dialogar. Abs! "],
["4-6-minimos-quadrados-com-restricoes-lineares.html", "4.6 M√≠nimos quadrados com restri√ß√µes lineares", " 4.6 M√≠nimos quadrados com restri√ß√µes lineares A caracter√≠stica mais importante de um modelo estat√≠stico √© a sua flexibilidade. Esse termo pode ser entendido de v√°rias formas, mas neste texto vamos considerar que um modelo √© flex√≠vel se ele explica de forma coerente uma ampla gama de fen√¥menos reais. Pensando assim, a regress√£o linear pode ser considerada um modelo flex√≠vel, j√° que muitas rela√ß√µes funcionais cotidianas s√£o do tipo \\(y = \\beta x\\). √â justamente por causa dessa flexibilidade que a boa e velha regress√£o de m√≠nimos quadrados √© t√£o usada, at√© mesmo aonde n√£o deveria. O seu uso √© t√£o indiscriminado que uma vez, em aula, um professor extraordinariamente admir√°vel me disse que ‚Äú90% dos problemas do mundo podem ser resolvidos com uma regress√£o linear‚Äù. Sendo bastante honesto, √© prov√°vel que o meu professor esteja certo, mas este texto n√£o √© sobre isso. Este √© um post sobre o que fazer quando a regress√£o linear simples n√£o basta. No que segue, vamos discutir uma pequena (e poderosa) extens√£o do modelo de regress√£o linear simples, mas antes de prosseguir para o problema propriamente dito (e sua implementa√ß√£o em R), vamos discutir da teoria que existe por tr√°s dele. 4.6.1 Regress√£o linear √© programa√ß√£o quadr√°tica Embora seja pouco enfatizado nos bacharelados de estat√≠stica, uma regress√£o linear pode ser formulada como um problema de programa√ß√£o quadr√°tica. Entrando nos detalhes, essa afirma√ß√£o deve-se a dois fatos: Existe uma teoria, que chama-se programa√ß√£o quadr√°tica, que soluciona problemas da forma \\[\\min_x \\Big(\\frac{1}{2}x&#39; Q x + c&#39; x\\Big),\\] onde \\(x \\in \\mathbb{R}^p\\) e \\(Q\\) e \\(c\\) tem dimens√µes que fazem a conta acima ter sentido. A teoria ocupa-se desenvolvendo algoritmos exatos e aproximados para obter solu√ß√µes desses problemas, inclusive com generaliza√ß√µes: \\[\\min_x \\Big(\\frac{1}{2}x&#39; Q x + c&#39; x\\Big), \\text{ sujeito a }Ax \\geq 0.\\] Uma regress√£o linear consiste em resolver \\[\\min_\\beta (Y - \\beta X)&#39;(Y-\\beta X),\\] que, com um pouco de √°lgebra, √© equivalente √† \\[ \\min_\\beta (-2Y&#39;X\\beta + \\beta&#39;X&#39;X\\beta).\\] Logo, tomando \\(Q = 2X&#39;X\\) e \\(c = \\frac{1}{2}X&#39;Y\\) tem-se que esse √© um problema de programa√ß√£o quadr√°tica, que por sua vez √© um problema convexo e que, segundo a teoria, tem uma √∫nica solu√ß√£o no ponto \\(\\beta = (X&#39;X)^{-1}X&#39;Y\\). 4.6.2 Uma regress√£o linear simples mais flex√≠vel Talvez o jeito mais simples de flexibilizar uma regress√£o linear no sentido mencionado no come√ßo desse texto √© restringir os seus par√¢metros. Em muitos contextos, esse √© o √∫nico jeito de colocar conhecimentos pr√©vios na modelagem1. Um caso bastante emblem√°tico aparece nas curvas de cr√©dito divulgadas pela ANBIMA2. L√°, ajusta-se um conjunto de curvas que depende de 6 par√¢metros e cada curva representa uma classifica√ß√£o de risco (que nem aquela em que o Brasil pode tomar downgrade3). Como os n√≠veis de risco est√£o ordenados, √© natural exigir que tamb√©m exista uma ordena√ß√£o entre as curvas. Sem entrar em detalhes, a ideia pode ser expressa assim: \\[\\beta_{AAA} &lt; \\beta_{AA} &lt; \\beta_{A} &lt; \\beta_{BBB} &lt; ...\\] O que √© que isso tem a ver com programa√ß√£o quadr√°tica? A resposta √© que a inequa√ß√£o acima pode ser escrita como \\(A\\beta \\geq 0\\), de tal forma j√° existe uma teoria para resolver uma regress√£o linear simples com restri√ß√µes desse tipo! Basta que ela seja vista como um problema de programa√ß√£o quadr√°tica. 4.6.3 O pacote quadprog Existe um pacote de R para quase tudo, ent√£o, como n√£o poderia deixar de ser, existe um pacote em R para resolver problemas do tipo: \\[\\min_x \\Big(\\frac{1}{2}x&#39; Q x + c&#39; x\\Big), \\text{ sujeito a }Ax \\geq 0.\\] Para ilustrar o seu uso, vamos considerar um exemplo. Vamos simular um conjunto de dados em que \\(\\beta_5 = 0.31, \\beta_4 = 0.43, \\beta_3 = 1.31, \\beta_2 = 2.19, \\beta_1 = 2.29\\) s√£o os valores reais que precisamos estimar, considere que vale \\[Y \\approx \\beta_1X_1 + \\beta_2X_2+\\beta_3X_3+\\beta_4X_4+\\beta_5X_5\\] e que o erro de regress√£o tem distribui√ß√£o normal. Se soubermos antecipadamente que valem as seguintes afirma√ß√µes \\[ \\beta_1,\\beta_2,\\beta_3,\\beta_4,\\beta_5 &gt; 0 \\text{ e } \\beta_1 &gt; \\beta_2 &gt; \\beta_3 &gt; \\beta_4 &gt; \\beta_5,\\] a minimiza√ß√£o de \\((Y-\\beta X)&#39;(Y-\\beta X)\\) pode ser resolvida usando a fun√ß√£o solve.QP. Tudo que precisamos fazer √© escrever o conjunto de inequa√ß√µes na forma \\(A\\beta \\geq 0\\). Mas isso √© bem f√°cil! Basta notar que as restri√ß√µes s√£o equivalentes √† \\[ \\left(\\begin{array}{cccc} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; -1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; -1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -1 \\\\ \\end{array}\\right) \\times \\left(\\begin{array}{c}\\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\\\ \\beta_4 \\\\ \\beta_5 \\end{array}\\right) \\geq 0.\\] Dessa forma, o problema est√° prontinho pra passar no moedor de carne, com uma √∫ltima ressalva. O problema resolvido no solve.QP √© \\[\\min_x \\Big(\\frac{1}{2}x&#39; Q x + c&#39; x\\Big), \\text{ sujeito a }A&#39;x \\geq 0,\\] ent√£o vamos ter que tomar o cuidado de passar as nossas restri√ß√µes atrav√©s do transposto da matriz que obtivemos acima. Isso resultar√° na matriz \\(A\\). Para checar como valeu a pena todo esse esfor√ßo, d√° uma olhada na diferen√ßa entre as estimativas! Os pontinhos vermelhos s√£o as estimativas do modelo irrestrito, enquanto as barras s√£o as estimativas do modelo com restri√ß√µes. 4.6.4 Conclus√µes Regress√£o linear simples √© um problema de programa√ß√£o quadr√°tica. Algumas restri√ß√µes interessantes podem ser escritas na forma \\(B\\beta \\geq 0\\). Programa√ß√£o quadr√°tica resolve regress√£o linear simples com restri√ß√µes lineares. Se em algum dia voc√™ topar com um bicho desses, o quadprog pode resolver o problema pra voc√™. A menos que voc√™ seja uma pessoa razo√°vel bayesiano.‚Ü© http://www.anbima.com.br/data/files/05/43/3E/84/E12D7510E7FCF875262C16A8/metodologia-curvas_20credito_20131104_v2_1_.pdf‚Ü© http://economia.estadao.com.br/noticias/geral,agravamento-da-crise-politica-eleva-risco-de-rebaixamento-do-brasil-diz-sep,70001824274‚Ü© "],
["4-7-filtros-de-bloom-em-r.html", "4.7 Filtros de Bloom em R", " 4.7 Filtros de Bloom em R Filtro de Bloom √© um algoritmo muito interessante para testar se um elemento pertence a um conjunto. Ele √© considerado uma estrutura de dados probabil√≠stica, ou seja, o resultado pode n√£o estar correto com alguma probabilidade. Especificamente para o filtro de bloom, existe a possibilidade de falsos positivos mas n√£o de falsos negativos: o algoritmo pode dizer que o elemento pertence ao conjunto, mas na verdade n√£o pertencer, mas nunca dir√° que ele n√£o pertence sendo que ele pertence. Bloom Filters s√£o √∫teis em diversas situa√ß√µes, geralmente relacionadas ao ganho de velocidade e de espa√ßo que o seu uso pode trazer. Muitos sistemas de bancos de dados usam bloom filters para reduzir o n√∫mero de buscas no disco (ex. Cassandra). O Medium usa para evitar recomendar uma pa«µina que voc√™ j√° leu. Recentemente, encontraram at√© aplica√ß√µes para bloom filters em machine learning. Nesse post vamos implementar uma vers√£o simplificada, nada otimizada dos filtros de Bloom em R. Mas antes disso, vale a pena ler o verbete da Wikipedia sobre o assunto. Essencialmente, um filtro de bloom √© um vetor de TRUEs e FALSES de tamanho \\(m\\). Inicializamos esse vetor com FALSES. Em seguida para cada elemento do conjunto que voc√™ deseja representar pelo filtro, repetimos o seguinte processo: Hasheamos o elemento usando \\(k\\) fun√ß√µes de hash diferentes. Cada uma dessas fun√ß√µes indicar√° um elemento do vetor que deve ser marcado como TRUE. Armazenamos ent√£o esse vetor de bits. S√£o os valores de \\(m\\) e de \\(k\\) que controlam a probabilidade de falsos positivos. Veja como podemos criar uma fun√ß√£o em R para fazer essas opera√ß√µes. Essa fun√ß√£o inicializa o vetor de bits de tamanho \\(m\\) com FALSES e em seguida, para cada uma das \\(k\\) fun√ß√µes de hash (no caso apenas variamos a semente do hash MurMur32) e para cada elemento de x calculamos o elemento do vetor vec que deve se tornar TRUE. No final, ela retorna o vetor vec, onde armazenamos como atributos os par√¢metros usados na sua constru√ß√£o. library(digest) library(magrittr) criar_vetor_de_bits &lt;- function(x, m = 1000, k = 7){ vec &lt;- rep(FALSE, m) for (i in 1:k) { for (j in 1:length(x)) { hash &lt;- digest(x[j], algo = &quot;murmur32&quot;, serialize = FALSE, seed = i) %&gt;% Rmpfr::mpfr(base = 16) %% m %&gt;% as.integer() vec[hash + 1] &lt;- TRUE } } # armazenamos os par√¢metros usados na constru√ß√£o attributes(vec) &lt;- list(m = m, k= k) return(vec) } Dado um conjunto de strings, podemos criar o vetor de bits que o representa. vect &lt;- criar_vetor_de_bits(c(&quot;eu&quot;, &quot;pertenco&quot;, &quot;ao&quot;, &quot;conjunto&quot;, &quot;de&quot;, &quot;strings&quot;), m = 1000, k = 7) Agora vamos definir uma fun√ß√£o que verifica se uma string pertence ao conjunto, dada apenas a representa√ß√£o dos bits desse conjunto. Hasheamos o elemento que desejamos verificar a presen√ßa no conjunto com a primeira fun√ß√£o de hash. Se ela indicar um elemento do vetor que j√° est√° marcado com TRUE ent√£o continuamos, se n√£o, retorna FALSE indicando que o elemento n√£o pertence ao conjunto. Continuamos at√© acabarem as fun√ß√µes de hash ou at√© 1 FALSE ter sido retornado. verificar_presenca &lt;- function(x, vetor_de_bits){ k &lt;- attr(vetor_de_bits, &quot;k&quot;) m &lt;- attr(vetor_de_bits, &quot;m&quot;) for(i in 1:k){ hash &lt;- digest(x, algo = &quot;murmur32&quot;, serialize = FALSE, seed = i) %&gt;% Rmpfr::mpfr(base = 16) %% m %&gt;% as.integer() if(!vetor_de_bits[hash + 1]) { return(FALSE) } } return(TRUE) } verificar_presenca(&quot;nao&quot;, vect) verificar_presenca(&quot;eu&quot;, vect) verificar_presenca(&quot;abc&quot;, vect) Com m = 1000 e k = 7 n√£o consegui encontrar nenhum falso positivo, mas basta diminuir o tamanho de m e de k que encontraremos. No verbete da Wikipedia a conta est√° bonitinha mas de fato a probabilidade de falsos positivos pode ser estimada em fun√ß√£o dos par√¢metros \\(k\\) e \\(m\\) e \\(n\\) (tamanho do conjunto representado) √© dada por \\[(1 - e^{-kn/m})^k\\] No caso apresentado, a probabilidade de colis√£o √© de 1.991256e-10. "],
["4-8-modelando-a-variancia-da-normal.html", "4.8 Modelando a vari√¢ncia da normal", " 4.8 Modelando a vari√¢ncia da normal Verificar as suposi√ß√µes dos modelos √© muito importante quando fazemos infer√™ncia estat√≠stica. Em particular, a suposi√ß√£o de homocedasticidade4 dos modelos de regress√£o linear √© especialmente importante, pois modifica o c√°lculo de erros padr√£o, intervalos de confian√ßa e valores-p. Neste post, vou mostrar tr√™s pacotes do R que ajustam modelos da forma \\[ Y_i = \\beta_0 + \\sum_{k=1}^p\\beta_kx_{ik} + \\epsilon_i, \\ i = 1,\\ldots,n\\] \\[ \\epsilon_{i} \\sim \\textrm{N}(0,\\sigma_i), \\ i = 1,\\ldots,n \\ \\textrm{independentes, com }\\sigma_i^2 = \\alpha x_i^2. \\] Al√©m de mostrar como se faz, tamb√©m vou ilustrar o desempenho dos pacotes em um exemplo simulado. O modelo que gerar√° os dados do exemplo ter√° a seguinte forma funcional \\[ Y_i = \\beta x_i + \\epsilon_i, \\ i = 1,...n \\] \\[ \\epsilon_i \\sim N(0, \\sigma_i)\\text{ independentes, com }\\sigma_i = \\alpha\\sqrt{|x_i|},\\] e os par√¢metros do modelo ser√£o os valores \\(\\beta = 1\\) e \\(\\alpha = 4\\). A heterocedasticidade faz com que os pontos desenhem um cone ao redor da reta de regress√£o. 4.8.1 Usando o pacote gamlss Quando se ajusta um GAMLSS, voc√™ pode modelar os par√¢metros de loca√ß√£o, escala e curtose ao mesmo tempo em que escolhe a distribui√ß√£o dos dados dentre uma grande gama de op√ß√µes. Escolhendo a distribui√ß√£o normal e modelando apenas os par√¢metros de loca√ß√£o e escala, o GAMLSS ajusta modelos lineares normais com heterocedasticidade. No c√≥digo abaixo, o par√¢metro formula = Y ~ X-1 indica que a fun√ß√£o de regress√£o ser√° constitu√≠da por um preditor linear em X sem intercepto. J√° o par√¢metro sigma.formula = ~X2-1 indica que o desvio padr√£o ser√° modelado por um preditor linear em X2 (ou raiz de X), tamb√©m sem intercepto. FALSE GAMLSS-RS iteration 1: Global Deviance = 17872.29 FALSE GAMLSS-RS iteration 2: Global Deviance = 17870.67 FALSE GAMLSS-RS iteration 3: Global Deviance = 17870.67 Conforme descrito no sum√°rio abaixo, a estimativa de alfa est√° muito abaixo do valor simulado. FALSE ****************************************************************** FALSE Family: c(&quot;NO&quot;, &quot;Normal&quot;) FALSE FALSE Call: gamlss::gamlss(formula = Y ~ X - 1, sigma.formula = ~X2 - FALSE 1, family = NO(), data = dataset) FALSE FALSE Fitting method: RS() FALSE FALSE ------------------------------------------------------------------ FALSE Mu link function: identity FALSE Mu Coefficients: FALSE Estimate Std. Error t value Pr(&gt;|t|) FALSE X 0.996942 0.005131 194.3 &lt;2e-16 *** FALSE --- FALSE Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 FALSE FALSE ------------------------------------------------------------------ FALSE Sigma link function: log FALSE Sigma Coefficients: FALSE Estimate Std. Error t value Pr(&gt;|t|) FALSE X2 0.1791449 0.0009606 186.5 &lt;2e-16 *** FALSE --- FALSE Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 FALSE FALSE ------------------------------------------------------------------ FALSE No. of observations in the fit: 1000 FALSE Degrees of Freedom for the fit: 2 FALSE Residual Deg. of Freedom: 998 FALSE at cycle: 3 FALSE FALSE Global Deviance: 17870.67 FALSE AIC: 17874.67 FALSE SBC: 17884.49 FALSE ****************************************************************** 4.8.2 Usando o pacote dglm Quando se ajusta um Modelo Linear Generalizado Duplo (MLGD em portugu√™s e DGLM em ingl√™s), voc√™ tem uma flexibilidade parecida com a de um GAMLSS. Entretanto, voc√™ n√£o pode definir um modelo para a curtose e a classe de distribui√ß√µes dispon√≠vel √© bem menor. O c√≥digo abaixo, similar ao utilizado para ajustar o GAMLSS, ajusta um DGLM aos dados simulados. Novamente, verifica-se que o alfa estimado est√° muito distante do verdadeiro alfa. FALSE FALSE Call: dglm(formula = Y ~ X - 1, dformula = ~X2 - 1, family = gaussian, FALSE data = dataset, method = &quot;reml&quot;) FALSE FALSE Mean Coefficients: FALSE Estimate Std. Error t value Pr(&gt;|t|) FALSE X 0.9969432 0.008981392 111.001 0 FALSE (Dispersion Parameters for gaussian family estimated as below ) FALSE FALSE Scaled Null Deviance: 27197.48 on 1000 degrees of freedom FALSE Scaled Residual Deviance: 3090.08 on 999 degrees of freedom FALSE FALSE Dispersion Coefficients: FALSE Estimate Std. Error z value Pr(&gt;|z|) FALSE X2 0.3577322 0.001166004 306.8019 0 FALSE (Dispersion parameter for Gamma family taken to be 2 ) FALSE FALSE Scaled Null Deviance: 1628.301 on 1000 degrees of freedom FALSE Scaled Residual Deviance: 6526.59 on 999 degrees of freedom FALSE FALSE Minus Twice the Log-Likelihood: 17870.76 FALSE Number of Alternating Iterations: 18 4.8.3 Usando o pacote rstan Stan √© uma linguagem de programa√ß√£o voltada para descrever e manipular objetos probabil√≠sticos, como por exemplo vari√°veis aleat√≥rias, processos estoc√°sticos, distribui√ß√µes de probabilidades etc. Essa linguagem foi projetada para tornar intuitivo e simples o ajuste de modelos estat√≠sticos. Em particular, a forma de descrever modelos bayesianos √© bem c√¥moda. O stan possui v√°rias interfaces para R. A mais b√°sica √© o rstan, que ser√° utilizada aqui. A principal fun√ß√£o desse pacote √© a fun√ß√£o rstan, que possui dois par√¢metros b√°sicos: um par√¢metro model_code =, que recebe um c√≥digo que descreve o modelo na linguagem stan. um par√¢metro data =, que recebe uma lista contendo os inputs do modelo, tais como dados coletados, par√¢metros de distribui√ß√µes a priori, etc. Embora esse seja o m√≠nimo que a fun√ß√£o precisa, tamb√©m podemos passar outras componentes. O par√¢metro verbose = FALSE faz com que a fun√ß√£o n√£o imprima nada enquanto roda e o par√¢metro control = list(...) passa uma lista de op√ß√µes de controle para o algoritmo de ajuste. O retorno da fun√ß√£o stan() √© um objeto do tipo stanfit, que pode ser sumarizado da mesma forma que outros modelos em R, utilizando a fun√ß√£o summary() e a fun√ß√£o plot(). O c√≥digo abaixo ilustra a aplica√ß√£o da fun√ß√£o stan() ao nosso exemplo. A figura abaixo descreve os intervalos de credibilidade obtidos para cada par√¢metro do modelo. O ponto central de cada intervalo representa as estimativas pontuais dos par√¢metros. Como se nota, as estimativas do modelo utilizando stan est√£o bem pr√≥ximas dos valores verdadeiros. Uma regress√£o linear √© homoced√°stica quando a variabilidade dos erros n√£o depende das covari√°veis do modelo.‚Ü© "],
["5-reflexoes.html", "Cap√≠tulo 5 Reflex√µes ", " Cap√≠tulo 5 Reflex√µes "],
["5-1-manifesto-tidy.html", "5.1 Manifesto tidy", " 5.1 Manifesto tidy Autor: Daniel Dificuldade baixa program O manifesto das ferramentas tidy do Hadley Wickham √© um dos documentos mais importantes sobre R dos √∫ltimos tempos. Esse documento formaliza uma s√©rie de princ√≠pios que norteiam o desenvolvimento dotidyverse. O tidyverse √© um conjunto de pacotes que, por compartilharem esses princ√≠pios do manifesto tidy, podem ser utilizados naturalmente em conjunto. Pode-se dizer que existe o R antes do tidyverse e o R depois do tidyverse. A linguagem mudou muito, a comunidade abra√ßou fortemente o uso desses princ√≠pios e tem muita gente criando pacotes para conversar uns com os outros dessa forma. No entanto, usar a filosofia tidy n√£o √© a √∫nica forma de fazer pacotes do R, existem muitos pacotes excelentes que n√£o utilizam essa filosofia. Como o pr√≥prio texto diz ‚ÄúO contr√°rio de tidyverse n√£o √© o messyverse, e sim muitos outros universos de pacotes interconectados.‚Äù. Os princ√≠pios fundamentais do tidyverse s√£o: Reutilizar estruturas de dados existentes. Organizar fun√ß√µes simples usando o pipe. Aderir √† programa√ß√£o funcional. Projetado para ser usado por seres humanos. No texto do manifesto tidy cada um dos lemas √© descrito de forma detalhada. Aqui, selecionei os aspectos que achei mais importante de cada um deles. 5.1.1 Reutilizar estruturas de dados existentes Quando poss√≠vel, √© melhor utilizar estruturas de dados comuns do que criar uma estrutura espec√≠fica para o seu pacote. Geralmente, √© melhor reutilizar uma estrutura existente mesmo que ela n√£o se encaixe perfeitamente. 5.1.2 Organizar fun√ß√µes simples usando o pipe Fa√ßa com que suas fun√ß√µes sejam o mais simples poss√≠veis. Uma fun√ß√£o deve poder ser descrita com apenas uma senten√ßa. A sua fun√ß√£o deve fazer uma transforma√ß√£o no estilo copy-on-modify ou ter um efeito colateral. Nunca os dois. O nome das fun√ß√µes devem ser verbos. Exceto quando as fun√ß√µes do pacote usam sempre o mesmo verbo. Ex: adicionar ou modificar. 5.1.3 Aderir √† programa√ß√£o funcional O R √© uma linguagem de programa√ß√£o funcional, n√£o lute contra isso. 5.1.4 Projetado para ser usado por seres humanos Desenvolva o seu pacote para ser usado por humanos. Foque em ter uma API clara para que voc√™ escreva o c√≥digo de maneira intuitiva e r√°pida. Efici√™ncia dos algoritmos √© uma preocupa√ß√£o secund√°ria, pois gastamos mais tempo escrevendo o c√≥digo do que executando. Esses princ√≠pios s√£o bem gerais, mas ajudam bastante a tomar decis√µes quando estamos escrevendo o nosso c√≥digo. Para finalizar, clique aqui e veja uma busca no Github por ‚Äútidy‚Äù em reposit√≥rios de R. S√£o mais de 3000 resultados, quase todos seguindo essa filosofia e estendendo o universo arrumado. "],
["5-2-eu-a-estatistica-e-a-programacao.html", "5.2 Eu, a Estat√≠stica e a programa√ß√£o", " 5.2 Eu, a Estat√≠stica e a programa√ß√£o Autor: William Dificuldade baixa program ‚Äî N√£o sabia que nessa cidade a cada 20 minutos atropelam um homem? ‚Äî Nossa! E como est√° o coitado? O epis√≥dio ‚ÄúEstat√≠sticas‚Äù do Chaves foi o meu primeiro contato com o conceito de Estat√≠stica (pelo menos que eu possa me lembrar). Claro que naquela √©poca, com 5 ou 6 anos, eu nunca imaginaria que seria essa a minha profiss√£o. Assim como o Quico e o Chaves, eu n√£o fazia muita ideia do que as ‚Äúsenhoras estat√≠sticas‚Äù&quot; eram e continuei sem saber de fato at√© entrar na gradua√ß√£o, em 2007. Reassistindo o epis√≥dio, depois de mais de dez anos estudando a disciplina, me identifiquei bastante com a dificuldade que a Dona Florinda e o Professor Girafales t√™m para explicar o que s√£o estat√≠sticas, o que antes via apenas como uma escada para as piadas que constroem a cena. Quando saio da minha bolha de colegas de faculdade e trabalho, percebo o quanto conceitos b√°sicos de probabilidade e estat√≠stica s√£o desconhecidos pela popula√ß√£o, mesmo aqueles presentes no dia a dia. Recentemente, lendo um coment√°rio de um radialista sobre a derrota do S√£o Paulo para o Coritiba, na rodada 18 do Campeonato Brasileiro, uma frase me chamou aten√ß√£o. ‚ÄúAo iniciar o jogo dessa quinta √† noite, o Tricolor, de acordo com as estat√≠sticas, tinha 1,78% de chances de vencer o Coritiba.‚Äù A tese do radialista √© que a probabilidade dos quatro grandes times de S√£o Paulo vencerem na mesma rodada do campeonato √© de 1,78%, a frequ√™ncia relativa desse evento na era de pontos corridos do Campeonato Brasileiro. Como o S√£o Paulo foi o √∫ltimo grande a jogar e os outros tr√™s j√° haviam vencido, o pobre tricolor paulista teve suas chances reduzidas pelas estat√≠sticas e acabou perdendo o jogo. Essa interpreta√ß√£o com certeza pode ser refutada por v√°rios motivos, mas o que mais me incomodou foi o desconhecimento de probabilidade condicional, ou simplesmente como novas informa√ß√µes modificam as probabilidades dos eventos. Encucado, eu deixei uma resposta, cuja parte central √© essa: Mesmo se consider√°ssemos que a probabilidade dos 4 grandes de SP ganharem numa rodada n√£o dependesse de fatores como a fase dos times, os advers√°rios, o momento do campeonato etc., esse n√∫mero, 1,78%, seria a probabilidade dos quatro ganharem antes da rodada come√ßar. Dado que j√° sabemos que os outros tr√™s ganharam, e considerando que o resultado desses jogos n√£o influenciam o jogo do SP, a probabilidade do evento em quest√£o ocorrer passa a ser apenas a probabilidade do SP ganhar o jogo dele. Em seguida, recebi alguns coment√°rios de outros torcedores dizendo (jocosamente) que n√£o tinham entendido nada do que escrevi. Comecei ent√£o a refletir sobre o assunto, pensando no quanto a minha explica√ß√£o poderia estar confusa e de que forma poderia ter explicado melhor, no quanto as pessoas n√£o costumam se esfor√ßar para entender temas que elas n√£o dominam e no quanto a falta de uma base matem√°tica adequada atrapalha nessas horas. Eu acredito que a Probabilidade e a Estat√≠stica s√£o v√≠timas da onda do ‚Äú√© legal odiar Matem√°tica‚Äù, que muitas pessoas se orgulham de surfar. Crian√ßas saem da escola com um conhecimento superficial dessas disciplinas (quando muito!), achando que √© tudo uma quest√£o de jogar dados, calcular m√©dias e fazer gr√°ficos. Comunicadores sofrem para interpretar os n√∫meros de uma pesquisa e pesquisadores encaram a an√°lise estat√≠stica como o grande vil√£o que os separa da publica√ß√£o. Felizmente, esse comportamento vem mudando, mesmo que a passos lentos. Profissionais est√£o buscando cursos de data science e programa√ß√£o, empresas est√£o promovendo cursos para qualificarem seus funcion√°rios e o mercado para estat√≠sticos continua um c√©u estrelado, tanto para analistas e programadores quanto para educadores. Eu vejo essa mudan√ßa, e as pessoas ao meu redor tamb√©m a veem. Mas o exemplo que citei acima me faz acreditar que preciso espiar fora da minha bolha. Por isso, vou come√ßar uma pequena s√©rie de posts, dando a minha opini√£o sobre algumas coisas que orbitam a educa√ß√£o estat√≠stica e a programa√ß√£o, com o objetivo de gerar reflex√£o e discuss√£o sobre o assunto. A Estat√≠stica vem crescendo como carreira, o estat√≠stico vem se tornando cada vez mais protagonista, e vejo esse momento como o ideal para melhorarmos a educa√ß√£o da nossa disciplina. Dividirei o texto nos seguintes t√≥picos: Por que amar a Estat√≠stica? Preconceitos no aprendizado Estat√≠stica e programa√ß√£o Espero que esses posts possam contribuir para mostrarmos para mais gente a import√¢ncia da Estat√≠stica e da Computa√ß√£o e por que amamos tanto trabalhar com essas ci√™ncias. 5.2.1 Por que amar a estat√≠stica? Escolher uma profiss√£o, para quem tem esse privil√©gio, √© uma das decis√µes mais importantes das nossas vidas. Aos 17, 18 anos, a imaturidade, o pouco auto-conhecimento e a falta de informa√ß√£o sobre as alternativas podem nos desviar da op√ß√£o que nos vestiria melhor, um erro que muitas vezes nunca ser√° reparado. √Äs vezes, eu me pergunto o que levou amigos e conhecido a escolherem suas profiss√µes na hora do vestibular. No meu caso, eu quase segui um caminho da ‚Äúprofiss√µes da moda‚Äù. O que me impediu de prestar Administra√ß√£o foi descobrir, na hora da inscri√ß√£o, que era uma carreira da √°rea de Humanas, n√£o Exatas. Sim, eu era bem perdido. Na √©poca, a segunda fase da FUVEST era diferente para cada √°rea, e eu n√£o tinha perspectiva nenhuma de ir bem se tivesse que fazer uma prova dissertativa de Hist√≥ria e Geografia em vez de Matem√°tica e F√≠sica, disciplinas que eu dominava muito mais. Por isso, ap√≥s uma (muito breve) pesquisa na internet, fui convencido a prestar Estat√≠stica, e o que me convenceu foi a frase ‚Äú[‚Ä¶] envolve bastante matem√°tica e o mercado de trabalho √© muito bom‚Äù. Foi baseado nisso que eu tomei uma das decis√µes mais importantes da minha vida e era basicamente tudo o que eu sabia sobre a carreira quando comecei a gradua√ß√£o. Prestar vestibular para Estat√≠stica foi um tiro no escuro t√£o certeiro que √†s vezes me pego pensando em destino e esoterismos desse tipo. Durante a gradua√ß√£o, conheci pessoas que n√£o tiveram a mesma sorte e acabaram desistindo nos primeiros semestres, que s√£o bem pesados na matem√°tica. A primeira parte da informa√ß√£o que eu tinha sobre realmente estava certa, e o curso de Estat√≠stica pode assustar quem n√£o estiver na pegada de provar v√°rios teoremas. Mas, neste post, n√£o quero falar sobre as dificuldades da escalada, mas sim sobre a vista ao se chegar ao topo. Conforme fui conhecendo a Estat√≠stica, eu descobri que ela √© a profiss√£o mais nerd que existe5. Eu sustento essa opini√£o porque a melhor defini√ß√£o de nerd que j√° escutei √© ‚Äúpessoa ama aprender‚Äù e, gra√ßas √† Estat√≠stica, tenho a oportunidade de estudar muita coisa diferente. Nesses dez anos como estat√≠stico, j√° fiz an√°lises na √°rea de engenharia, finan√ßas, educa√ß√£o, jornalismo, zoologia, farm√°cia, fisioterapia, medicina, psicologia, odontologia, educa√ß√£o f√≠sica‚Ä¶ e essas s√£o apenas as que eu lembrei de cabe√ßa. Estat√≠stica √© parte essencial do m√©todo cient√≠fico e est√° presente em todas as ci√™ncias. Pegar trabalhos novos para um estat√≠stico nerd √© extremamente motivante, porque n√£o √© apenas uma troca de tempo por dinheiro, √© uma √≥tima chance para aprender coisas novas. A Estat√≠stica te estimula a ser curioso e criativo, e isso √© o que eu mais amo nela. Outra coisa para se amar √© o mercado de trabalho. A segunda parte da informa√ß√£o que eu tinha tamb√©m estava correta: o mercado de trabalho para o estat√≠stico √© excelente! N√£o s√≥ pelo n√∫mero de oportunidades, mas pela gama de lugares diferentes onde somos necess√°rios. N√£o vou listar aqui porque √© praticamente qualquer √°rea. E sobre sal√°rios, como diria um professor do IME, d√° para alimentar fam√≠lias. Apesar de ter sido um dos poucos dos meus colegas a n√£o mergulhar de cabe√ßa no mercado, j√° tive duas experi√™ncias. A primeira foi como estagi√°rio em um banco, onde aprendi bastante sobre o que eu n√£o queria fazer na vida. Tudo o que eu fazia era rodar modelos pr√©-estabelecidos para gerar relat√≥rios pr√©-formatados. Tinha aprendido tanta coisa legal na gradua√ß√£o e n√£o podia usar nada, o que me fazia sentir como um p√°ssaro engaiolado. A segunda foi no Instituto Butantan, onde eu era o √∫nico estat√≠stico ao lado de v√°rios bi√≥logos, farmac√™uticos e veterin√°rios. Foi uma √≥tima experi√™ncia, na qual conheci muita gente bacana e aprendi muita coisa de biologia, farm√¢cia e controle de qualidade. Trabalhar com pessoas diferentes de voc√™, com outras formas de pensar, √© outra parte legal de ser estat√≠stico. O pessoal do Butantan me ensinou bastante, principalmente sobre como a ci√™ncia e a pesquisa funcionam na pr√°tica. Al√©m disso, foi l√° que nasceu o meu interesse em ensinar Estat√≠stica. Bom, essa foi uma parte da hist√≥ria de como eu me apaixonei pela Estat√≠stica. Talvez eu n√£o tenha acrescentado nada se voc√™ j√° compartilha desse sentimento, mas espero que esse texto chegue a pessoas que ainda estejam escolhendo sua profiss√£o e jogue luz sobre essa alternativa. Essa √© a hora de mudarmos gr√°ficos como esse. Resumindo: Estat√≠stica √© a profiss√£o para quem gosta de aprender. Um bom estat√≠stico no mercado √© uma crian√ßa com cart√£o de cr√©dito numa loja de brinquedos. No pr√≥ximo post desta s√©rie, vou levantar um pouco de pol√™mica desabafando sobre alguns preconceitos de aprendizagem. At√© breve! 5.2.2 Preconceitos no aprendizado Volta e meia eu escuto as famosas frases FALSE [1] &quot;Eu sou de Humanas&quot; &quot;Eu sou de Exatas&quot; &quot;Eu sou de Biol√≥gicas&quot; de algu√©m tentando justificar por que n√£o vai fazer alguma coisa. Muitas vezes, n√£o passa de uma brincadeira na hora de dividir a conta do bar. Muitas outras, me soa como uma desculpa pronta para n√£o encarar problemas complicados. Para mim, todo aprendizado √© dif√≠cil, n√£o acho que existe conhecimento de gra√ßa, ent√£o realmente importa se ele √© de Humanas, Exatas ou Biol√≥gicas? A divis√£o do conhecimento nessas tr√™s grandes √°reas tem a sua import√¢ncia organizacional, mas acaba motivando muita gente a criar limita√ß√µes que n√£o existem de verdade. Por que algu√©m de Exatas n√£o conseguiria assimilar as ideias de um texto filos√≥fico? Ou por que algu√©m de Biol√≥gicas n√£o conseguiria aprender C√°lculo? Acredito que cada um de n√≥s tem afinidade por uma das √°reas e maior facilidade em estudar um t√≥pico ou outro. Normal. Mas fico triste quando vejo pessoas inteligentes se diminuindo ao se declararem incapazes de aprender outras compet√™ncias que n√£o a delas. Sei que essa incapacidade n√£o existe e enxergo apenas como uma forma sofisticada de dizer ‚ÄúEstou com pregui√ßa‚Äù. Uma das belezas da Estat√≠stica √© nos fazer perder esse preconceito. Por mais que tenhamos nossos gostos, descobrimos que n√£o estamos presos ao dom√≠nio de apenas uma √°rea. N√≥s trabalhamos com pessoas que pensam e aprendem de formas diferentes de nossa e constru√≠mos juntos pontes para trocarmos conhecimento. Ser estat√≠stico √© n√£o ter medo de estudar, seja l√° o que for. Trazendo a reflex√£o aqui para o nosso mundinho, j√° ouvi muitas vezes colegas dizendo, principalmente na Gradua√ß√£o, que n√£o usam o R porque ele √© dif√≠cil ou porque n√£o gostam de programar. A minha opini√£o sobre a primeira desculpa est√° nos par√°grafos acima. Sobre a segunda, vou discutir no pr√≥ximo e √∫ltimo post desta s√©rie: a rela√ß√£o entre Estat√≠stica e programa√ß√£o. Resumindo a √≥pera: sempre vamos apanhar aprendendo, e vamos apanhar mais ainda quando n√£o gostamos do que estamos estudando, mas cedo ou tarde, com a quantidade certa de esfor√ßo, o conhecimento d√° as caras. E no bar, na hora de dividir a conta, o problema n√£o √© voc√™ ser de Humanas. O problema √© a sua pregui√ßa. :D 5.2.3 Estat√≠stica e programa√ß√£o N√£o importa a √°rea de atua√ß√£o, a maior parte do dia do estat√≠stico √© atr√°s do computador. E desse tempo, a maior parte √© atr√°s de um (geralmente √∫nico) programa estat√≠stico. Os principais programas hoje em dia permitem a execu√ß√£o das etapas essenciais de uma an√°lise: intera√ß√£o com banco de dados, transforma√ß√£o, cria√ß√£o de visualiza√ß√µes e modelagem. Alguns v√£o al√©m e auxiliam na comunica√ß√£o dos resultados. Tamb√©m √© comum a exist√™ncia de ambientes de programa√ß√£o, mesmo quando o programa √© bem estruturado no point and click. Eu considero a programa√ß√£o primordial para um estat√≠stico. Ela nos d√° a liberdade para sermos criativos, para n√£o nos limitarmos em t√©cnicas que algu√©m criou e todo mundo usa. Para mim, um estat√≠stico que n√£o sabe/gosta de programar √© igual a um piloto que s√≥ dirige carro autom√°tico. √â por isso que o R √© uma ferramenta t√£o incr√≠vel para se trabalhar. Ele pega a sua m√£o no momento em que voc√™ recebe a base de dados, estando ela arrumada ou n√£o, e s√≥ solta depois da sua an√°lise estar devidamente divulgada. Para cada problema, o R te fornece todas as pe√ßas e te deixa montar do jeito que quiser. E mesmo quando uma pe√ßa n√£o existe, voc√™ mesmo pode cri√°-la ou pedir socorro para a comunidade mais que fant√°stica de erreiros pelo mundo. Claro que aprender a programar √© bem custoso. Para quem nunca foi familiar com a computa√ß√£o, vai ser um caminho bem tortuoso no in√≠cio. Mas como discutimos no √∫ltimo post, n√£o existe aprendizado de gra√ßa, e por mais que voc√™ n√£o goste de estudar programa√ß√£o, √© um investimento com retorno mais do que garantido. 5.2.4 Wrap-up Fazendo um resum√£o do que falamos at√© aqui, podemos enumerar os seguintes itens: A Estat√≠stica √© uma disciplina fant√°stica, principalmente para quem gosta de aprender, e o mercado est√° bombando. Aprender Estat√≠stica √© dif√≠cil, assim como todo conhecimento. O que vai limitar a sua capacidade de aprender √© o quanto voc√™ vai conseguir dominar a sua pregui√ßa de estudar. A Estat√≠stica e a programa√ß√£o andam lado a lado. O Estat√≠stico que sabe programar tem muito mais poder para resolver problemas complicados. O R √© o ambiente mais legal para trabalhar com Estat√≠stica. :D √â isso! Espero que possamos continuar discutindo o quanto √© legal trabalhar com Estat√≠stica e que cada vez mais pessoas se interessem por esse caminho dif√≠cil, mas recompensador. Se voc√™ ainda v√™ alguma conota√ß√£o negativa na palavra nerd, mande as minha lembran√ßas aos anos 90. üòâ‚Ü© "],
["5-3-o-fluxo-do-web-scraping.html", "5.3 O Fluxo do Web Scraping", " 5.3 O Fluxo do Web Scraping Autor: Caio Dificuldade m√©dia program Web scraping (ou raspagem web) n√£o √© nada mais que o ato de coletar dados da internet. Hoje em dia √© muito comum termos acesso r√°pido e f√°cil a qualquer conjunto de informa√ß√µes pela web, mas raramente esses dados est√£o estruturados e em uma forma de f√°cil obten√ß√£o pelo usu√°rio. Isso faz com que precisemos aprender a coletar esses dados por conta pr√≥pria. Neste post vou descrever o fluxo do web scraping, um passo a passo para explicar aos iniciantes como funciona a cria√ß√£o de um raspador. 5.3.1 O fluxo Caso voc√™ j√° tenha visto o fluxo da ci√™ncia de dados descrito por Hadley Wickham, o fluxo do web scraping vai ser bastante simples de entender. Todos os itens a seguir v√£o se basear neste diagrama: Cada verbo indica um fase do processo de raspar dados da internet. A caixa azulada no meio do diagrama denominada reprodu√ß√£o indica um procedimento iterativo que devemos repetir at√© que a coleta funcione, mas, de resto, o fluxo √© um processo linear. Nas pr√≥ximas se√ß√µes, vamos explorar um exemplo bem simples para entender como esses passos se dariam no mundo real: extrair os t√≠tulos de artigos da Wikip√©dia. 5.3.1.1 Identificar O primeiro passo do fluxo se chama identificar porque nele identificamos a informa√ß√£o que vamos coletar. Aqui precisamos entender bem qual √© a estrutura das p√°ginas que queremos raspar e tra√ßar um plano para extrair tudo que precisamos. No nosso exemplo, precisar√≠amos entrar em algumas p√°ginas da Wikip√©dia para entender se os t√≠tulos se comportam da mesma forma em todas. Como a Wikip√©dia √© um site organizado, todos os t√≠tulos s√£o criados da mesma forma em absolutamente todos os artigos. 5.3.1.2 Navegar Agora precisamos entender de onde vem o dado que queremos extrair. Esse passo pode ser extremamente simples, mas de vez em quando ele se tornara algo bastante complexo. Usando as ferramentas de desenvolvedor do nosso navegador, vamos navegar para encontrar a fonte dos dados. Sem entrar em muitos detalhes, poder√≠amos analisar o networking do navegador para entender as chamadas HTTP que s√£o feitas, poder√≠amos estudar os resultados das fun√ß√µes JavaScript invocadas pela p√°gina e assim por diante. No nosso caso, como escolhi um exemplo simples, precisamos apenas inspecionar o elemento do t√≠tulo e ver qual √© o seu XPath (basicamente o endere√ßo do elemento no HTML da p√°gina): //*[@id=&quot;firstHeading&quot;]. 5.3.1.3 Replicar Se tiv√©ssemos que fazer v√°rias requests HTTP para chegar at√© a informa√ß√£o que queremos, seria aqui em que tentar√≠amos replicar essas chamadas. Neste passo √© importante compreender absolutamente tudo que a p√°gina est√° fazendo para trazer o conte√∫do at√© voc√™, ent√£o √© necess√°rio analisar o seu networking a fim de entender tais requests e seus respectivos queries. No nosso caso, basta fazer uma chamada GET para obter a p√°gina do artigo desejado. Tamb√©m se faz necess√°rio salvar a p√°gina localmente para que possamos dar continuidade ao fluxo. url &lt;- &quot;https://en.wikipedia.org/wiki/R_(programming_language)&quot; httr::GET(url, httr::write_disk(&quot;~/Desktop/wiki.html&quot;)) 5.3.1.4 Parsear O anglicismo parsear vem do verbo to parse, que quer dizer algo como analisar ou estudar, mas que, no contexto do web scraping, significa extrair os dados desejados de um arquivo HTML. Aqui vamos usar a informa√ß√£o obtida no passo 2 para retirar do arquivo que chamei de wiki.html o t√≠tulo do artigo. &quot;~/Desktop/wiki.html&quot; %&gt;% xml2::read_html() %&gt;% rvest::html_node(xpath = &quot;//*[@id=&#39;firstHeading&#39;]&quot;) %&gt;% rvest::html_text() #&gt; [1] &quot;R (programming language)&quot; 5.3.1.5 Validar Se tivermos feito tudo certo at√© agora, validar os resultados ser√° uma tarefa simples. Precisamos apenas reproduzir o procedimento descrito at√© agora para algumas outras p√°ginas de modo verificar se estamos de fato extraindo corretamente tudo o que queremos. Caso encontremos algo de errado precisamos voltar ao passo 3, tentar replicar corretamente o comportamento do site e parsear os dados certos nas p√°ginas. 5.3.1.6 Iterar O √∫ltimo passo consiste em colocar o nosso scraper em produ√ß√£o. Aqui, ele j√° deve estar funcionando corretamente para todos os casos desejados e estar pronto para raspar todos os dados dos quais precisamos. Na maior parte dos casos isso consiste em encapsular o scraper em uma fun√ß√£o que recebe uma s√©rie de links e aplica o mesmo procedimento em cada um. Se quisermos aumentar a efici√™ncia desse processo, podemos paralelizar ou distribuir o nosso raspador. scraper &lt;- function(url, path) { httr::GET(url, httr::write_disk(path)) path %&gt;% xml2::read_html() %&gt;% rvest::html_node(xpath = &quot;//*[@id=&#39;firstHeading&#39;]&quot;) %&gt;% rvest::html_text() } purrr::map2_chr(links, paths, scraper) 5.3.2 Conclus√£o Fazer um scraper n√£o √© uma tarefa f√°cil, mas, se toda vez seguirmos um m√©todo consistente e robusto, podemos melhorar um pouco o nosso trabalho. O fluxo do web scraping tenta ser este m√©todo, englobando em passos simples e razoavelmente bem definidos essa arte que √© fazer raspadores web. "],
["5-4-tidy-data-teste-t-pareado-e-modelos-mistos.html", "5.4 Tidy Data, Teste t Pareado e Modelos Mistos", " 5.4 Tidy Data, Teste t Pareado e Modelos Mistos Autor: Daniel Dificuldade alta model O que teste \\(t\\)-pareado, modelos mistos e tidy data podem ter em comum? 5.4.1 Tidy Data Para come√ßar, vamos relemebrar o que √© tidy data para depois seguir ao ponto do post. Tidy data √© um conceito introduzido pelo Hadley Wickham neste paper. Esse paper √©, para mim, o melhor artigo do Hadley. A primeira frase da defini√ß√£o cita Tolstoi e diz: Like families, tidy datasets are all alike but every messy dataset is messy in its own way. ‚Äì Leo Tolstoi Essa frase resume a vida de qualquer um que trabalha ou j√° trabalhou com an√°lise de dados. O ponto mais importante do que significa tidy data tamb√©m est√° neste primeiro par√°grafo: s√£o datasets em que a estrutura dos dados est√° ligada com o seu significado. A forma padronizada √©: Cada vari√°vel √© uma coluna de uma tabela Cada observa√ß√£o √© uma linha de uma tabela Cada tipo de unidade observacional forma uma tabela O exemplo c√°ssico √© o seguinte. Primeiro vamos ver um banco de dados desarrumado. Pais Idh2015 Idh2014 Brasil 0.754 0.755 Argentina 0.827 0.836 Chile 0.847 0.832 Esse dataset est√° desarrumado pois existem duas colunas Idh2015 e Idh2014 que representam a mesma vari√°vel: IDH e uma vari√°vel impl√≠cita ANO, que tamb√©m aparece nesta duas colunas. A forma tidy de representar este dataset seria: Pais ano idh Brasil 2015 0.754 Argentina 2015 0.827 Chile 2015 0.847 Brasil 2014 0.755 Argentina 2014 0.836 Chile 2014 0.832 5.4.2 O que isso tem a ver com teste \\(t\\)-pareado e modelos mistos? Suponha que queremos inferir se houve alguma mudan√ßa na m√©dia do IDH de um ano para o outro. Ou seja, testar se a m√©dia do IDH de 2015 √© diferente da m√©dia do IDH de 2014. Vamos considerar um banco de dados simulado: Uma forma de fazer isso √© usar o teste \\(t\\)-pareado, ensinado nos cursos introdut√≥rios de estat√≠stica. Basicamente o que ele faz √© testar se a m√©dia da diferen√ßa entre o IDH2015 e o IDH 2014 √© diferente de zero. Isso √© diferente de um teste \\(t\\) usual, pois o teste \\(t\\)-pareado ajusta o seu c√°lculo da vari√¢ncia para considerar que existem duas fontes de incerteza, eventualmente correlacionadas. No R a forma mais natural de fazer isso √©: Note que o nosso banco de dados est√° desarrumado e mesmo assim foi muito simples fazer esse teste no R. Agora vamos arrumar o banco de dados. Agora para fazer o mesmo teste, poder√≠amos filtrar o banco de dados duas vezes, por exemplo: Paired t-test data: df$idh[df$ano == 2015] and df$idh[df$ano == 2014] t = 27.355, df = 49, p-value &lt; 2.2e-16 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 0.09000554 0.10427822 sample estimates: mean of the differences 0.09714188 Mas a√≠ estamos voltando para a forma desarrumada para fazer o teste. Outra forma de fazer √© considerar essa compara√ß√£o de m√©dias como um problema de regress√£o em que a suposi√ß√£o independ√™ncia das observa√ß√µes n√£o √© v√°lida, uma vez que para cada pa√≠s, os IDHs de 2014 e de 2015 s√£o correlacionados. Vamos ajustar um modelo com efeitos aleat√≥rios para esse problema e comparar os resultados. Linear mixed-effects model fit by REML Data: df AIC BIC logLik -184.7518 -174.4119 96.37588 Random effects: Formula: ~1 | Pais (Intercept) Residual StdDev: 0.3009017 0.01775584 Fixed effects: idh ~ as.factor(ano) Value Std.Error DF t-value p-value (Intercept) 0.4840132 0.04262795 49 11.35436 0 as.factor(ano)2015 0.0971419 0.00355117 49 27.35491 0 Correlation: (Intr) as.factor(ano)2015 -0.042 Standardized Within-Group Residuals: Min Q1 Med Q3 Max -1.88877770 -0.44544521 -0.01239249 0.39934207 1.84475543 Number of Observations: 100 Number of Groups: 50 Estamos interessados em comparar a signific√¢ncia do efeito fixo da vari√°vel ano nesse modelo com a do teste \\(t\\)-pareado. Veja que no caso a estat√≠stica \\(t\\) do testes √© id√™ntica: 27.35. Vimos que a forma como os dados est√£o estruturados no seu banco de dados pode influenciar a opera√ß√£o utilizada para realizar a an√°lise. Se ele estivesse na forma desarrumada o mais natural seria aplicar um teste \\(t\\)-pareado, se ele estivesse em formado tidy o natural seria usar um modelo misto. Em seu paper, Hadley argumenta que a maioria dos softwares esperam que o seu banco de dados esteja arrumado no sentido de que cada vari√°vel √© uma coluna e cada observa√ß√£o √© uma linha. "],
["referencias.html", "Refer√™ncias", " Refer√™ncias "]
]
