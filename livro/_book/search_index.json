[
["index.html", "Como faz no R Capítulo 1 Introdução ", " Como faz no R Curso-R 06 de janeiro de 2019 Capítulo 1 Introdução "],
["1-1-objetivos.html", "1.1 Por quê ler esse livro", " 1.1 Por quê ler esse livro "],
["1-2-organizacao.html", "1.2 Organização", " 1.2 Organização "],
["2-analises.html", "Capítulo 2 Análises", " Capítulo 2 Análises "],
["3-tutoriais.html", "Capítulo 3 Tutoriais", " Capítulo 3 Tutoriais "],
["4-reflexoes.html", "Capítulo 4 Reflexões ", " Capítulo 4 Reflexões "],
["4-1-manifesto-tidy.html", "4.1 Manifesto tidy", " 4.1 Manifesto tidy Autor: Daniel Dificuldade baixa program O manifesto das ferramentas tidy do Hadley Wickham é um dos documentos mais importantes sobre R dos últimos tempos. Esse documento formaliza uma série de princípios que norteiam o desenvolvimento dotidyverse. O tidyverse é um conjunto de pacotes que, por compartilharem esses princípios do manifesto tidy, podem ser utilizados naturalmente em conjunto. Pode-se dizer que existe o R antes do tidyverse e o R depois do tidyverse. A linguagem mudou muito, a comunidade abraçou fortemente o uso desses princípios e tem muita gente criando pacotes para conversar uns com os outros dessa forma. No entanto, usar a filosofia tidy não é a única forma de fazer pacotes do R, existem muitos pacotes excelentes que não utilizam essa filosofia. Como o próprio texto diz “O contrário de tidyverse não é o messyverse, e sim muitos outros universos de pacotes interconectados.”. Os princípios fundamentais do tidyverse são: Reutilizar estruturas de dados existentes. Organizar funções simples usando o pipe. Aderir à programação funcional. Projetado para ser usado por seres humanos. No texto do manifesto tidy cada um dos lemas é descrito de forma detalhada. Aqui, selecionei os aspectos que achei mais importante de cada um deles. 4.1.1 Reutilizar estruturas de dados existentes Quando possível, é melhor utilizar estruturas de dados comuns do que criar uma estrutura específica para o seu pacote. Geralmente, é melhor reutilizar uma estrutura existente mesmo que ela não se encaixe perfeitamente. 4.1.2 Organizar funções simples usando o pipe Faça com que suas funções sejam o mais simples possíveis. Uma função deve poder ser descrita com apenas uma sentença. A sua função deve fazer uma transformação no estilo copy-on-modify ou ter um efeito colateral. Nunca os dois. O nome das funções devem ser verbos. Exceto quando as funções do pacote usam sempre o mesmo verbo. Ex: adicionar ou modificar. 4.1.3 Aderir à programação funcional O R é uma linguagem de programação funcional, não lute contra isso. 4.1.4 Projetado para ser usado por seres humanos Desenvolva o seu pacote para ser usado por humanos. Foque em ter uma API clara para que você escreva o código de maneira intuitiva e rápida. Eficiência dos algoritmos é uma preocupação secundária, pois gastamos mais tempo escrevendo o código do que executando. Esses princípios são bem gerais, mas ajudam bastante a tomar decisões quando estamos escrevendo o nosso código. Para finalizar, clique aqui e veja uma busca no Github por “tidy” em repositórios de R. São mais de 3000 resultados, quase todos seguindo essa filosofia e estendendo o universo arrumado. "],
["4-2-eu-a-estatistica-e-a-programacao.html", "4.2 Eu, a Estatística e a programação", " 4.2 Eu, a Estatística e a programação Autor: William Dificuldade baixa program — Não sabia que nessa cidade a cada 20 minutos atropelam um homem? — Nossa! E como está o coitado? O episódio “Estatísticas” do Chaves foi o meu primeiro contato com o conceito de Estatística (pelo menos que eu possa me lembrar). Claro que naquela época, com 5 ou 6 anos, eu nunca imaginaria que seria essa a minha profissão. Assim como o Quico e o Chaves, eu não fazia muita ideia do que as “senhoras estatísticas”&quot; eram e continuei sem saber de fato até entrar na graduação, em 2007. Reassistindo o episódio, depois de mais de dez anos estudando a disciplina, me identifiquei bastante com a dificuldade que a Dona Florinda e o Professor Girafales têm para explicar o que são estatísticas, o que antes via apenas como uma escada para as piadas que constroem a cena. Quando saio da minha bolha de colegas de faculdade e trabalho, percebo o quanto conceitos básicos de probabilidade e estatística são desconhecidos pela população, mesmo aqueles presentes no dia a dia. Recentemente, lendo um comentário de um radialista sobre a derrota do São Paulo para o Coritiba, na rodada 18 do Campeonato Brasileiro, uma frase me chamou atenção. “Ao iniciar o jogo dessa quinta à noite, o Tricolor, de acordo com as estatísticas, tinha 1,78% de chances de vencer o Coritiba.” A tese do radialista é que a probabilidade dos quatro grandes times de São Paulo vencerem na mesma rodada do campeonato é de 1,78%, a frequência relativa desse evento na era de pontos corridos do Campeonato Brasileiro. Como o São Paulo foi o último grande a jogar e os outros três já haviam vencido, o pobre tricolor paulista teve suas chances reduzidas pelas estatísticas e acabou perdendo o jogo. Essa interpretação com certeza pode ser refutada por vários motivos, mas o que mais me incomodou foi o desconhecimento de probabilidade condicional, ou simplesmente como novas informações modificam as probabilidades dos eventos. Encucado, eu deixei uma resposta, cuja parte central é essa: Mesmo se considerássemos que a probabilidade dos 4 grandes de SP ganharem numa rodada não dependesse de fatores como a fase dos times, os adversários, o momento do campeonato etc., esse número, 1,78%, seria a probabilidade dos quatro ganharem antes da rodada começar. Dado que já sabemos que os outros três ganharam, e considerando que o resultado desses jogos não influenciam o jogo do SP, a probabilidade do evento em questão ocorrer passa a ser apenas a probabilidade do SP ganhar o jogo dele. Em seguida, recebi alguns comentários de outros torcedores dizendo (jocosamente) que não tinham entendido nada do que escrevi. Comecei então a refletir sobre o assunto, pensando no quanto a minha explicação poderia estar confusa e de que forma poderia ter explicado melhor, no quanto as pessoas não costumam se esforçar para entender temas que elas não dominam e no quanto a falta de uma base matemática adequada atrapalha nessas horas. Eu acredito que a Probabilidade e a Estatística são vítimas da onda do “é legal odiar Matemática”, que muitas pessoas se orgulham de surfar. Crianças saem da escola com um conhecimento superficial dessas disciplinas (quando muito!), achando que é tudo uma questão de jogar dados, calcular médias e fazer gráficos. Comunicadores sofrem para interpretar os números de uma pesquisa e pesquisadores encaram a análise estatística como o grande vilão que os separa da publicação. Felizmente, esse comportamento vem mudando, mesmo que a passos lentos. Profissionais estão buscando cursos de data science e programação, empresas estão promovendo cursos para qualificarem seus funcionários e o mercado para estatísticos continua um céu estrelado, tanto para analistas e programadores quanto para educadores. Eu vejo essa mudança, e as pessoas ao meu redor também a veem. Mas o exemplo que citei acima me faz acreditar que preciso espiar fora da minha bolha. Por isso, vou começar uma pequena série de posts, dando a minha opinião sobre algumas coisas que orbitam a educação estatística e a programação, com o objetivo de gerar reflexão e discussão sobre o assunto. A Estatística vem crescendo como carreira, o estatístico vem se tornando cada vez mais protagonista, e vejo esse momento como o ideal para melhorarmos a educação da nossa disciplina. Dividirei o texto nos seguintes tópicos: Por que amar a Estatística? Preconceitos no aprendizado Estatística e programação Espero que esses posts possam contribuir para mostrarmos para mais gente a importância da Estatística e da Computação e por que amamos tanto trabalhar com essas ciências. 4.2.1 Por que amar a estatística? Escolher uma profissão, para quem tem esse privilégio, é uma das decisões mais importantes das nossas vidas. Aos 17, 18 anos, a imaturidade, o pouco auto-conhecimento e a falta de informação sobre as alternativas podem nos desviar da opção que nos vestiria melhor, um erro que muitas vezes nunca será reparado. Às vezes, eu me pergunto o que levou amigos e conhecido a escolherem suas profissões na hora do vestibular. No meu caso, eu quase segui um caminho da “profissões da moda”. O que me impediu de prestar Administração foi descobrir, na hora da inscrição, que era uma carreira da área de Humanas, não Exatas. Sim, eu era bem perdido. Na época, a segunda fase da FUVEST era diferente para cada área, e eu não tinha perspectiva nenhuma de ir bem se tivesse que fazer uma prova dissertativa de História e Geografia em vez de Matemática e Física, disciplinas que eu dominava muito mais. Por isso, após uma (muito breve) pesquisa na internet, fui convencido a prestar Estatística, e o que me convenceu foi a frase “[…] envolve bastante matemática e o mercado de trabalho é muito bom”. Foi baseado nisso que eu tomei uma das decisões mais importantes da minha vida e era basicamente tudo o que eu sabia sobre a carreira quando comecei a graduação. Prestar vestibular para Estatística foi um tiro no escuro tão certeiro que às vezes me pego pensando em destino e esoterismos desse tipo. Durante a graduação, conheci pessoas que não tiveram a mesma sorte e acabaram desistindo nos primeiros semestres, que são bem pesados na matemática. A primeira parte da informação que eu tinha sobre realmente estava certa, e o curso de Estatística pode assustar quem não estiver na pegada de provar vários teoremas. Mas, neste post, não quero falar sobre as dificuldades da escalada, mas sim sobre a vista ao se chegar ao topo. Conforme fui conhecendo a Estatística, eu descobri que ela é a profissão mais nerd que existe1. Eu sustento essa opinião porque a melhor definição de nerd que já escutei é “pessoa ama aprender” e, graças à Estatística, tenho a oportunidade de estudar muita coisa diferente. Nesses dez anos como estatístico, já fiz análises na área de engenharia, finanças, educação, jornalismo, zoologia, farmácia, fisioterapia, medicina, psicologia, odontologia, educação física… e essas são apenas as que eu lembrei de cabeça. Estatística é parte essencial do método científico e está presente em todas as ciências. Pegar trabalhos novos para um estatístico nerd é extremamente motivante, porque não é apenas uma troca de tempo por dinheiro, é uma ótima chance para aprender coisas novas. A Estatística te estimula a ser curioso e criativo, e isso é o que eu mais amo nela. Outra coisa para se amar é o mercado de trabalho. A segunda parte da informação que eu tinha também estava correta: o mercado de trabalho para o estatístico é excelente! Não só pelo número de oportunidades, mas pela gama de lugares diferentes onde somos necessários. Não vou listar aqui porque é praticamente qualquer área. E sobre salários, como diria um professor do IME, dá para alimentar famílias. Apesar de ter sido um dos poucos dos meus colegas a não mergulhar de cabeça no mercado, já tive duas experiências. A primeira foi como estagiário em um banco, onde aprendi bastante sobre o que eu não queria fazer na vida. Tudo o que eu fazia era rodar modelos pré-estabelecidos para gerar relatórios pré-formatados. Tinha aprendido tanta coisa legal na graduação e não podia usar nada, o que me fazia sentir como um pássaro engaiolado. A segunda foi no Instituto Butantan, onde eu era o único estatístico ao lado de vários biólogos, farmacêuticos e veterinários. Foi uma ótima experiência, na qual conheci muita gente bacana e aprendi muita coisa de biologia, farmâcia e controle de qualidade. Trabalhar com pessoas diferentes de você, com outras formas de pensar, é outra parte legal de ser estatístico. O pessoal do Butantan me ensinou bastante, principalmente sobre como a ciência e a pesquisa funcionam na prática. Além disso, foi lá que nasceu o meu interesse em ensinar Estatística. Bom, essa foi uma parte da história de como eu me apaixonei pela Estatística. Talvez eu não tenha acrescentado nada se você já compartilha desse sentimento, mas espero que esse texto chegue a pessoas que ainda estejam escolhendo sua profissão e jogue luz sobre essa alternativa. Essa é a hora de mudarmos gráficos como esse. Resumindo: Estatística é a profissão para quem gosta de aprender. Um bom estatístico no mercado é uma criança com cartão de crédito numa loja de brinquedos. No próximo post desta série, vou levantar um pouco de polêmica desabafando sobre alguns preconceitos de aprendizagem. Até breve! 4.2.2 Preconceitos no aprendizado Volta e meia eu escuto as famosas frases FALSE [1] &quot;Eu sou de Humanas&quot; &quot;Eu sou de Exatas&quot; &quot;Eu sou de Biológicas&quot; de alguém tentando justificar por que não vai fazer alguma coisa. Muitas vezes, não passa de uma brincadeira na hora de dividir a conta do bar. Muitas outras, me soa como uma desculpa pronta para não encarar problemas complicados. Para mim, todo aprendizado é difícil, não acho que existe conhecimento de graça, então realmente importa se ele é de Humanas, Exatas ou Biológicas? A divisão do conhecimento nessas três grandes áreas tem a sua importância organizacional, mas acaba motivando muita gente a criar limitações que não existem de verdade. Por que alguém de Exatas não conseguiria assimilar as ideias de um texto filosófico? Ou por que alguém de Biológicas não conseguiria aprender Cálculo? Acredito que cada um de nós tem afinidade por uma das áreas e maior facilidade em estudar um tópico ou outro. Normal. Mas fico triste quando vejo pessoas inteligentes se diminuindo ao se declararem incapazes de aprender outras competências que não a delas. Sei que essa incapacidade não existe e enxergo apenas como uma forma sofisticada de dizer “Estou com preguiça”. Uma das belezas da Estatística é nos fazer perder esse preconceito. Por mais que tenhamos nossos gostos, descobrimos que não estamos presos ao domínio de apenas uma área. Nós trabalhamos com pessoas que pensam e aprendem de formas diferentes de nossa e construímos juntos pontes para trocarmos conhecimento. Ser estatístico é não ter medo de estudar, seja lá o que for. Trazendo a reflexão aqui para o nosso mundinho, já ouvi muitas vezes colegas dizendo, principalmente na Graduação, que não usam o R porque ele é difícil ou porque não gostam de programar. A minha opinião sobre a primeira desculpa está nos parágrafos acima. Sobre a segunda, vou discutir no próximo e último post desta série: a relação entre Estatística e programação. Resumindo a ópera: sempre vamos apanhar aprendendo, e vamos apanhar mais ainda quando não gostamos do que estamos estudando, mas cedo ou tarde, com a quantidade certa de esforço, o conhecimento dá as caras. E no bar, na hora de dividir a conta, o problema não é você ser de Humanas. O problema é a sua preguiça. :D 4.2.3 Estatística e programação Não importa a área de atuação, a maior parte do dia do estatístico é atrás do computador. E desse tempo, a maior parte é atrás de um (geralmente único) programa estatístico. Os principais programas hoje em dia permitem a execução das etapas essenciais de uma análise: interação com banco de dados, transformação, criação de visualizações e modelagem. Alguns vão além e auxiliam na comunicação dos resultados. Também é comum a existência de ambientes de programação, mesmo quando o programa é bem estruturado no point and click. Eu considero a programação primordial para um estatístico. Ela nos dá a liberdade para sermos criativos, para não nos limitarmos em técnicas que alguém criou e todo mundo usa. Para mim, um estatístico que não sabe/gosta de programar é igual a um piloto que só dirige carro automático. É por isso que o R é uma ferramenta tão incrível para se trabalhar. Ele pega a sua mão no momento em que você recebe a base de dados, estando ela arrumada ou não, e só solta depois da sua análise estar devidamente divulgada. Para cada problema, o R te fornece todas as peças e te deixa montar do jeito que quiser. E mesmo quando uma peça não existe, você mesmo pode criá-la ou pedir socorro para a comunidade mais que fantástica de erreiros pelo mundo. Claro que aprender a programar é bem custoso. Para quem nunca foi familiar com a computação, vai ser um caminho bem tortuoso no início. Mas como discutimos no último post, não existe aprendizado de graça, e por mais que você não goste de estudar programação, é um investimento com retorno mais do que garantido. 4.2.4 Wrap-up Fazendo um resumão do que falamos até aqui, podemos enumerar os seguintes itens: A Estatística é uma disciplina fantástica, principalmente para quem gosta de aprender, e o mercado está bombando. Aprender Estatística é difícil, assim como todo conhecimento. O que vai limitar a sua capacidade de aprender é o quanto você vai conseguir dominar a sua preguiça de estudar. A Estatística e a programação andam lado a lado. O Estatístico que sabe programar tem muito mais poder para resolver problemas complicados. O R é o ambiente mais legal para trabalhar com Estatística. :D É isso! Espero que possamos continuar discutindo o quanto é legal trabalhar com Estatística e que cada vez mais pessoas se interessem por esse caminho difícil, mas recompensador. Se você ainda vê alguma conotação negativa na palavra nerd, mande as minha lembranças aos anos 90. 😉↩ "],
["4-3-o-fluxo-do-web-scraping.html", "4.3 O Fluxo do Web Scraping", " 4.3 O Fluxo do Web Scraping Autor: Caio Dificuldade média program Web scraping (ou raspagem web) não é nada mais que o ato de coletar dados da internet. Hoje em dia é muito comum termos acesso rápido e fácil a qualquer conjunto de informações pela web, mas raramente esses dados estão estruturados e em uma forma de fácil obtenção pelo usuário. Isso faz com que precisemos aprender a coletar esses dados por conta própria. Neste post vou descrever o fluxo do web scraping, um passo a passo para explicar aos iniciantes como funciona a criação de um raspador. 4.3.1 O fluxo Caso você já tenha visto o fluxo da ciência de dados descrito por Hadley Wickham, o fluxo do web scraping vai ser bastante simples de entender. Todos os itens a seguir vão se basear neste diagrama: Cada verbo indica um fase do processo de raspar dados da internet. A caixa azulada no meio do diagrama denominada reprodução indica um procedimento iterativo que devemos repetir até que a coleta funcione, mas, de resto, o fluxo é um processo linear. Nas próximas seções, vamos explorar um exemplo bem simples para entender como esses passos se dariam no mundo real: extrair os títulos de artigos da Wikipédia. 4.3.1.1 Identificar O primeiro passo do fluxo se chama identificar porque nele identificamos a informação que vamos coletar. Aqui precisamos entender bem qual é a estrutura das páginas que queremos raspar e traçar um plano para extrair tudo que precisamos. No nosso exemplo, precisaríamos entrar em algumas páginas da Wikipédia para entender se os títulos se comportam da mesma forma em todas. Como a Wikipédia é um site organizado, todos os títulos são criados da mesma forma em absolutamente todos os artigos. 4.3.1.2 Navegar Agora precisamos entender de onde vem o dado que queremos extrair. Esse passo pode ser extremamente simples, mas de vez em quando ele se tornara algo bastante complexo. Usando as ferramentas de desenvolvedor do nosso navegador, vamos navegar para encontrar a fonte dos dados. Sem entrar em muitos detalhes, poderíamos analisar o networking do navegador para entender as chamadas HTTP que são feitas, poderíamos estudar os resultados das funções JavaScript invocadas pela página e assim por diante. No nosso caso, como escolhi um exemplo simples, precisamos apenas inspecionar o elemento do título e ver qual é o seu XPath (basicamente o endereço do elemento no HTML da página): //*[@id=&quot;firstHeading&quot;]. 4.3.1.3 Replicar Se tivéssemos que fazer várias requests HTTP para chegar até a informação que queremos, seria aqui em que tentaríamos replicar essas chamadas. Neste passo é importante compreender absolutamente tudo que a página está fazendo para trazer o conteúdo até você, então é necessário analisar o seu networking a fim de entender tais requests e seus respectivos queries. No nosso caso, basta fazer uma chamada GET para obter a página do artigo desejado. Também se faz necessário salvar a página localmente para que possamos dar continuidade ao fluxo. url &lt;- &quot;https://en.wikipedia.org/wiki/R_(programming_language)&quot; httr::GET(url, httr::write_disk(&quot;~/Desktop/wiki.html&quot;)) 4.3.1.4 Parsear O anglicismo parsear vem do verbo to parse, que quer dizer algo como analisar ou estudar, mas que, no contexto do web scraping, significa extrair os dados desejados de um arquivo HTML. Aqui vamos usar a informação obtida no passo 2 para retirar do arquivo que chamei de wiki.html o título do artigo. &quot;~/Desktop/wiki.html&quot; %&gt;% xml2::read_html() %&gt;% rvest::html_node(xpath = &quot;//*[@id=&#39;firstHeading&#39;]&quot;) %&gt;% rvest::html_text() #&gt; [1] &quot;R (programming language)&quot; 4.3.1.5 Validar Se tivermos feito tudo certo até agora, validar os resultados será uma tarefa simples. Precisamos apenas reproduzir o procedimento descrito até agora para algumas outras páginas de modo verificar se estamos de fato extraindo corretamente tudo o que queremos. Caso encontremos algo de errado precisamos voltar ao passo 3, tentar replicar corretamente o comportamento do site e parsear os dados certos nas páginas. 4.3.1.6 Iterar O último passo consiste em colocar o nosso scraper em produção. Aqui, ele já deve estar funcionando corretamente para todos os casos desejados e estar pronto para raspar todos os dados dos quais precisamos. Na maior parte dos casos isso consiste em encapsular o scraper em uma função que recebe uma série de links e aplica o mesmo procedimento em cada um. Se quisermos aumentar a eficiência desse processo, podemos paralelizar ou distribuir o nosso raspador. scraper &lt;- function(url, path) { httr::GET(url, httr::write_disk(path)) path %&gt;% xml2::read_html() %&gt;% rvest::html_node(xpath = &quot;//*[@id=&#39;firstHeading&#39;]&quot;) %&gt;% rvest::html_text() } purrr::map2_chr(links, paths, scraper) 4.3.2 Conclusão Fazer um scraper não é uma tarefa fácil, mas, se toda vez seguirmos um método consistente e robusto, podemos melhorar um pouco o nosso trabalho. O fluxo do web scraping tenta ser este método, englobando em passos simples e razoavelmente bem definidos essa arte que é fazer raspadores web. "],
["4-4-tidy-data-teste-t-pareado-e-modelos-mistos.html", "4.4 Tidy Data, Teste t Pareado e Modelos Mistos", " 4.4 Tidy Data, Teste t Pareado e Modelos Mistos Autor: Daniel Dificuldade alta model O que teste \\(t\\)-pareado, modelos mistos e tidy data podem ter em comum? 4.4.1 Tidy Data Para começar, vamos relemebrar o que é tidy data para depois seguir ao ponto do post. Tidy data é um conceito introduzido pelo Hadley Wickham neste paper. Esse paper é, para mim, o melhor artigo do Hadley. A primeira frase da definição cita Tolstoi e diz: Like families, tidy datasets are all alike but every messy dataset is messy in its own way. – Leo Tolstoi Essa frase resume a vida de qualquer um que trabalha ou já trabalhou com análise de dados. O ponto mais importante do que significa tidy data também está neste primeiro parágrafo: são datasets em que a estrutura dos dados está ligada com o seu significado. A forma padronizada é: Cada variável é uma coluna de uma tabela Cada observação é uma linha de uma tabela Cada tipo de unidade observacional forma uma tabela O exemplo cássico é o seguinte. Primeiro vamos ver um banco de dados desarrumado. Pais Idh2015 Idh2014 Brasil 0.754 0.755 Argentina 0.827 0.836 Chile 0.847 0.832 Esse dataset está desarrumado pois existem duas colunas Idh2015 e Idh2014 que representam a mesma variável: IDH e uma variável implícita ANO, que também aparece nesta duas colunas. A forma tidy de representar este dataset seria: Pais ano idh Brasil 2015 0.754 Argentina 2015 0.827 Chile 2015 0.847 Brasil 2014 0.755 Argentina 2014 0.836 Chile 2014 0.832 4.4.2 O que isso tem a ver com teste \\(t\\)-pareado e modelos mistos? Suponha que queremos inferir se houve alguma mudança na média do IDH de um ano para o outro. Ou seja, testar se a média do IDH de 2015 é diferente da média do IDH de 2014. Vamos considerar um banco de dados simulado: Uma forma de fazer isso é usar o teste \\(t\\)-pareado, ensinado nos cursos introdutórios de estatística. Basicamente o que ele faz é testar se a média da diferença entre o IDH2015 e o IDH 2014 é diferente de zero. Isso é diferente de um teste \\(t\\) usual, pois o teste \\(t\\)-pareado ajusta o seu cálculo da variância para considerar que existem duas fontes de incerteza, eventualmente correlacionadas. No R a forma mais natural de fazer isso é: Note que o nosso banco de dados está desarrumado e mesmo assim foi muito simples fazer esse teste no R. Agora vamos arrumar o banco de dados. Agora para fazer o mesmo teste, poderíamos filtrar o banco de dados duas vezes, por exemplo: Paired t-test data: df$idh[df$ano == 2015] and df$idh[df$ano == 2014] t = 27.355, df = 49, p-value &lt; 2.2e-16 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 0.09000554 0.10427822 sample estimates: mean of the differences 0.09714188 Mas aí estamos voltando para a forma desarrumada para fazer o teste. Outra forma de fazer é considerar essa comparação de médias como um problema de regressão em que a suposição independência das observações não é válida, uma vez que para cada país, os IDHs de 2014 e de 2015 são correlacionados. Vamos ajustar um modelo com efeitos aleatórios para esse problema e comparar os resultados. Linear mixed-effects model fit by REML Data: df AIC BIC logLik -184.7518 -174.4119 96.37588 Random effects: Formula: ~1 | Pais (Intercept) Residual StdDev: 0.3009017 0.01775584 Fixed effects: idh ~ as.factor(ano) Value Std.Error DF t-value p-value (Intercept) 0.4840132 0.04262795 49 11.35436 0 as.factor(ano)2015 0.0971419 0.00355117 49 27.35491 0 Correlation: (Intr) as.factor(ano)2015 -0.042 Standardized Within-Group Residuals: Min Q1 Med Q3 Max -1.88877770 -0.44544521 -0.01239249 0.39934207 1.84475543 Number of Observations: 100 Number of Groups: 50 Estamos interessados em comparar a significância do efeito fixo da variável ano nesse modelo com a do teste \\(t\\)-pareado. Veja que no caso a estatística \\(t\\) do testes é idêntica: 27.35. Vimos que a forma como os dados estão estruturados no seu banco de dados pode influenciar a operação utilizada para realizar a análise. Se ele estivesse na forma desarrumada o mais natural seria aplicar um teste \\(t\\)-pareado, se ele estivesse em formado tidy o natural seria usar um modelo misto. Em seu paper, Hadley argumenta que a maioria dos softwares esperam que o seu banco de dados esteja arrumado no sentido de que cada variável é uma coluna e cada observação é uma linha. "],
["referencias.html", "Referências", " Referências "]
]
